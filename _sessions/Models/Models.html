<!DOCTYPE html>
<html>
  <head>
    <title>Models</title>
    <meta charset="utf-8">
    <meta name="author" content="Applied Machine Learning with R www.therbootcamp.com @therbootcamp" />
    <link href="libs/remark-css/default.css" rel="stylesheet" />
    <link rel="stylesheet" href="baselrbootcamp.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Models
### Applied Machine Learning with R<br/><a href='https://therbootcamp.github.io'>www.therbootcamp.com</a><br/><a href='https://twitter.com/therbootcamp'><span class="citation">@therbootcamp</span></a>
### January 2019

---


layout: true

&lt;div class="my-footer"&gt;&lt;span&gt;
&lt;a href="https://therbootcamp.github.io/"&gt;&lt;font color="#7E7E7E"&gt;Applied Machine Learning with R, January 2019&lt;/font&gt;&lt;/a&gt;
&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;
&lt;a href="https://therbootcamp.github.io/"&gt;&lt;font color="#7E7E7E"&gt;www.therbootcamp.com&lt;/font&gt;&lt;/a&gt;
&lt;/span&gt;&lt;/div&gt; 

---









# There is no free lunch

.pull-left35[

&lt;u&gt;Theorem&lt;/u&gt;

Given a finite set `\(V\)` and a finite set `\(S\)` of real numbers, &lt;high&gt;assume that `\(f:V\to S\)` is chosen at random&lt;/high&gt; according to uniform distribution on the set `\(S^{V}\)` of all possible functions from `\(V\)` to `\(S\)`. For the problem of optimizing `\(f\)` over the set `\(V\)`, &lt;high&gt;then no algorithm performs better than blind search.&lt;/high&gt;
&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;
&lt;a href="https://ti.arc.nasa.gov/m/profile/dhw/papers/78.pdf"&gt;Wolpert &amp; Macready, 1997, No Free Lunch Theorems for Optimization&lt;/a&gt;

]

.pull-right55[

&lt;p align="left"&gt;
  &lt;br&gt;
  &lt;img src="image/free_lunch.jpg" height=400px width=650px&gt;
&lt;/p&gt;

]

---

.pull-left4[

# Know your problem

&lt;u&gt;Bias-variance trade-off&lt;/u&gt;

&lt;font size=5&gt;&lt;high&gt;Error = Bias + Variance&lt;/high&gt;&lt;/font&gt;

&lt;br&gt;
Simply put...

&lt;high&gt;Bias&lt;/high&gt; arises from strong &lt;high&gt;model assumptions&lt;/high&gt; not being met by the environment.

&lt;high&gt;Bias&lt;/high&gt; arises from high &lt;high&gt;model flexibility&lt;/high&gt; fitting the noise in the data (i.e., overfitting).

&lt;br&gt;&lt;br&gt;
&amp;#8594; &lt;high&gt;Make strong assumptions&lt;/high&gt; (use simple models), if possible.

]

.pull-right45[

&lt;p align="left"&gt;
  &lt;br&gt;
  &lt;img src="image/bias_variance.png" height=580px&gt;
&lt;/p&gt;

]


---

.pull-left4[
# Linear or non-linear
&lt;br&gt;

One important model assumptions concerns linearity.
&lt;br&gt;&lt;br&gt;
&lt;high&gt;Linear models&lt;/high&gt; (`lm`, `glm`) make strong model assumptions. They are more often wrong, but also ceteris paribus &lt;high&gt;less prone to overfitting&lt;/high&gt;.

&lt;high&gt;Non-linear moels&lt;/high&gt; (everything else) make weaker model assumptions, leaving the exact relationship (more) open. They are are closer to the truth, but also ceteris paribus &lt;high&gt;more prone to overfitting&lt;/high&gt;. 


]

.pull-right5[

&lt;p align="center"&gt;
  &lt;br&gt;&lt;br&gt;&lt;br&gt;
  &lt;img src="image/linearity.png" height=480px&gt;
&lt;/p&gt;

]

---

.pull-left45[

# Kernel trick

&lt;high&gt;Transforms "input space" into new "feature space"&lt;/high&gt; to allows for object separation.

&lt;p align="center"&gt;
  &lt;img src="image/kernel_bw.png" height=160px&gt;
&lt;/p&gt;

Used in &lt;high&gt;Support Vector Machines&lt;/high&gt; (`method="svm"`) often using a &lt;high&gt;radial basis function&lt;/high&gt; (rdf).

&lt;p align="center"&gt;
  &lt;img src="image/rdf_kernel.png" width=300px&gt;
&lt;/p&gt;

Kernels &lt;high&gt;re-represent objects&lt;/high&gt; in terms of other objects!

]


.pull-right5[

&lt;p align="center"&gt;
  &lt;br&gt;&lt;br&gt;&lt;br&gt;
  &lt;img src="image/linearity.png" height=480px&gt;
&lt;/p&gt;

]


---

# Robustness

.pull-left5[

To nontheless produce robust predictions, machine learning models use a variety of `tricks`:

Decrease error tolerance
  SVM
Regularization
  Lasso
  Ridge
  Elastic Net
Binarize data
  Trees
Ensemble
Resampling

]

.pull-right5[

&lt;p align="center"&gt;
  &lt;img src="image/robustness_sel.png"&gt;
&lt;/p&gt;

]

---

# Regularization

.pull-left5[

Regularization is the process of adding model terms, usually &lt;high&gt;penalties for complexity&lt;/high&gt;, in order to prevent overfitting (or solve a problem in the first place).

|Name|Penalty|Caret|
|:----|:-----|:-----|
| AIC/BIC | `$$||\beta||_0$$` | - |
| Lasso | `\(||\beta||_1\)` | `method = "lasso` |
| Ridge | `\(||\beta||_2\)` | `method = "ridge` |
| Elastic net | `\(||\beta||_2 + ||\beta||_2\)` | `method = "elasticnet` |

]



.pull-right5[

&lt;img src="Models_files/figure-html/unnamed-chunk-3-1.png" style="display: block; margin: auto;" /&gt;

]

---

# Hedging

complex but sometimes necessary



---

# Binarization

complex but sometimes necessary


---

# Feature selection

complex but sometimes necessary


---

# Feature generation

complex but sometimes necessary


---

# Deep learning

complex but sometimes necessary




---

# Supervised learning


Non-Linearities can


---

# Feature engineering

Non-Linearities can



Einstein


---

Supervised learning

Regularization
  automatic feature selection

Kernel trick

Ensembles
  Bagging
  Ensemble
  Boosting

Feature generation
  Random Forest
  Neural networks
  CNN

Unspervised learning

  kernel trick

  k-means
  SVD
  PCA




---


# Practical

&lt;font size=6&gt;&lt;b&gt;&lt;a href="https://therbootcamp.github.io/Intro2DataScience_2018Oct/_sessions/Plotting/Plotting_practical.html"&gt;Link to practical&lt;/a&gt;
    </textarea>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false,
"ratio": "16:9"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function() {
  var d = document, s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})();</script>

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
  }
});
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
