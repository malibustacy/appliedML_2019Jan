<!DOCTYPE html>
<html>
  <head>
    <title>Optimization</title>
    <meta charset="utf-8">
    <meta name="author" content="Applied Machine Learning with R www.therbootcamp.com @therbootcamp" />
    <link href="libs/remark-css/default.css" rel="stylesheet" />
    <link rel="stylesheet" href="baselrbootcamp.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Optimization
## Regularization and Cross-Validation
### Applied Machine Learning with R<br/><a href='https://therbootcamp.github.io'>www.therbootcamp.com</a><br/><a href='https://twitter.com/therbootcamp'><span class="citation">@therbootcamp</span></a>
### January 2019

---


layout: true

&lt;div class="my-footer"&gt;&lt;span&gt;
&lt;a href="https://therbootcamp.github.io/"&gt;&lt;font color="#7E7E7E"&gt;Applied Machine Learning with R, January 2019&lt;/font&gt;&lt;/a&gt;
&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;
&lt;a href="https://therbootcamp.github.io/"&gt;&lt;font color="#7E7E7E"&gt;www.therbootcamp.com&lt;/font&gt;&lt;/a&gt;
&lt;/span&gt;&lt;/div&gt; 

---










.pull-left4[
&lt;br&gt;&lt;br&gt;
# Where we are

- &lt;high&gt;Train&lt;/high&gt; one of several models (&lt;high&gt;regression&lt;/high&gt;, &lt;high&gt;decision trees&lt;/high&gt;, and &lt;high&gt;random forests&lt;/high&gt;) on training data.

- Explore models - show regression coefficients, plot decision trees (etc)

- Assess model &lt;high&gt;prediction&lt;/high&gt; performance on &lt;high&gt;test&lt;/high&gt; data
    - Mean Absolute Error (MAE)

]

.pull-right55[

### Model Training

&lt;img src="image/model_training_flow.png" width="1442" style="display: block; margin: auto;" /&gt;

### Model Testing

&lt;img src="image/model_testing_flow.png" width="1439" style="display: block; margin: auto;" /&gt;


]


---

.pull-left4[
&lt;br&gt;&lt;br&gt;
# But...

How can I &lt;high&gt;estimate prediction error&lt;/high&gt; during model training?

How can I &lt;high&gt;optimise&lt;/high&gt; model training to &lt;high&gt;maximize prediction&lt;/high&gt; (not fitting!) performance?

How do I &lt;high&gt;avoid overfitting&lt;/high&gt; during training?

&lt;div class="figure" style="text-align: center"&gt;
&lt;img src="https://cdn-images-1.medium.com/max/1600/1*SBUK2QEfCP-zvJmKm14wGQ.png" alt="&amp;lt;font size = 4&amp;gt;hackernoon.com&amp;lt;/font&amp;gt;" width="100%" /&gt;
&lt;p class="caption"&gt;&lt;font size = 4&gt;hackernoon.com&lt;/font&gt;&lt;/p&gt;
&lt;/div&gt;

]

.pull-right55[

### Model Training

&lt;img src="image/model_training_flow.png" width="1442" style="display: block; margin: auto;" /&gt;

### Model Testing

&lt;img src="image/model_testing_flow.png" width="1439" style="display: block; margin: auto;" /&gt;


]


---


.pull-left4[
&lt;br&gt;&lt;br&gt;&lt;br&gt;
# Overfitting (Recap)

When a model is consistently &lt;high&gt;less accurate in predicting future data&lt;/high&gt; than in &lt;high&gt;fitting training data&lt;high&gt;, this is called &lt;high&gt;overfitting&lt;/high&gt;

Just because model A is better than model B in training, does not mean it will be better in testing!

Extremely flexible models that tend to overfit are like 'wolves in sheep's clothing'

]


.pull-right55[


&lt;br&gt;&lt;br&gt;
&lt;div class="figure" style="text-align: center"&gt;
&lt;img src="image/wolf_complex.png" alt="&amp;lt;font size = 4&amp;gt;victoriarollison.com (adapted)&amp;lt;/font&amp;gt;" width="100%" /&gt;
&lt;p class="caption"&gt;&lt;font size = 4&gt;victoriarollison.com (adapted)&lt;/font&gt;&lt;/p&gt;
&lt;/div&gt;


]

---


.pull-left4[
&lt;br&gt;&lt;br&gt;&lt;br&gt;

# Overfitting (Recap)

### How will we try to avoid overfitting?

Use regression models with &lt;high&gt;regularization&lt;/high&gt; terms, such as &lt;high&gt;ridge&lt;/high&gt; and &lt;high&gt;lasso&lt;/high&gt; which explicitly &lt;high&gt;punish model complexity&lt;/high&gt;.

Use &lt;high&gt;cross-validation&lt;/high&gt; to find &lt;high&gt;optimal tuning parameters&lt;/high&gt;, including regularization.

]

.pull-right55[

### Regularised Regression

&lt;div class="figure" style="text-align: center"&gt;
&lt;img src="image/lasso_penalty_eq.jpg" alt="L1 Lasso Penalty" width="100%" /&gt;
&lt;p class="caption"&gt;L1 Lasso Penalty&lt;/p&gt;
&lt;/div&gt;

### Cross Validation

&lt;img src="image/crossvalidation_4fold.png" width="90%" style="display: block; margin: auto;" /&gt;

]

---

.pull-left55[

# Tuning parameters (Recap)

### What are tuning parameters?

&lt;high&gt;Tuning parameters&lt;/high&gt; are parameters that &lt;high&gt;guide&lt;/high&gt; (aka. 'tune') a model during fitting.

- Decision trees: complexity tuning parameter &lt;high&gt;cp&lt;/high&gt;
- Random forests diversity tuning parameter &lt;high&gt;mtry&lt;/high&gt;
    
Tuning parameters never show up in the final model! They are only used to guide fitting.

There is not one 'best' tuning parameter, it always depends on your specific dataset.

]

.pull-right45[

&lt;img src="image/complexity_parameter.png" width="80%" style="display: block; margin: auto;" /&gt;

&lt;img src="image/mtry_parameter.png" width="80%" style="display: block; margin: auto;" /&gt;

]


---

# Regularised Regression

There are two common methods to fit penalised (aka regularised) regression models: Ridge and Lasso. Each penalises regression models for having large `\(\beta\)` values using the &lt;high&gt;Lambda tuning parameter&lt;/high&gt;

.pull-left5[

### Ridge

The Lasso penalty is known as the `\(\ell2\)` norm, where Beta weights are selected by minimising the following equation:

&lt;img src="image/ridge_penalty_eq.jpg" width="100%" style="display: block; margin: auto;" /&gt;

As `\(\lambda\)` increases, coefficients are pushed towards (but not necessarily exactly to) 0.

]

.pull-right45[


&lt;div class="figure" style="text-align: center"&gt;
&lt;img src="image/ridge_penalty_plot.png" alt="&amp;lt;font size = 4&amp;gt;James et al., ISLR&amp;lt;/font&amp;gt;" width="80%" /&gt;
&lt;p class="caption"&gt;&lt;font size = 4&gt;James et al., ISLR&lt;/font&gt;&lt;/p&gt;
&lt;/div&gt;

]




---

# Regularised Regression

There are two common methods to fit penalised (aka regularised) regression models: Ridge and Lasso. Each penalises regression models for having large `\(\beta\)` values using the &lt;high&gt;Lambda tuning parameter&lt;/high&gt;

.pull-left3[

### Ridge

To fit Ridge penalised regression in R, use `method = "glmnet`.

In the `tuneGrid` argument: 

- `alpha = 0` indicates the `\(\ell2\)` Ridge penalty.
- `lambda` = Vector of lambda tuning parameters values to try.

]

.pull-right65[
&lt;br&gt;

```r
# Train ridge penalised regression model in R

train(form = criterion ~ .,
      data = data_train,
      method = "glmnet",
      trControl = ctrl,
      tuneGrid = expand.grid(alpha = 0, # Ridge penalty
                              lambda = 1:100)) # Lambda
```

]

---

# Regularised Regression

There are two common methods to fit penalised (aka regularised) regression models: Ridge and Lasso. Each penalises regression models for having large `\(\beta\)` values using the &lt;high&gt;Lambda tuning parameter&lt;/high&gt;

.pull-left5[

### Lasso

The Lasso penalty is known as the `\(\ell1\)` norm, where Beta weights are selected by minimising the following equation:

&lt;img src="image/lasso_penalty_eq.jpg" width="100%" style="display: block; margin: auto;" /&gt;

As `\(\lambda\)` increases, coefficients are pushed towards 0, with some being forced to &lt;high&gt;exactly 0&lt;/high&gt;.

]

.pull-right45[

&lt;div class="figure" style="text-align: center"&gt;
&lt;img src="image/lasso_penalty_plot.png" alt="&amp;lt;font size = 4&amp;gt;James et al., ISLR&amp;lt;/font&amp;gt;" width="80%" /&gt;
&lt;p class="caption"&gt;&lt;font size = 4&gt;James et al., ISLR&lt;/font&gt;&lt;/p&gt;
&lt;/div&gt;

]

---

# Regularised Regression

There are two common methods to fit penalised (aka regularised) regression models: Ridge and Lasso. Each penalises regression models for having large `\(\beta\)` values using the &lt;high&gt;Lambda tuning parameter&lt;/high&gt;

.pull-left3[

### Lasso

To fit Lasso penalised regression in R, use `method = "glmnet`.

In the `tuneGrid` argument: 

- `alpha = 1` indicates the `\(\ell1\)` Lasso penalty
- `lambda` = Vector of lambda tuning parameters values to try.

]

.pull-right65[
&lt;br&gt;

```r
# Train Lasso penalised regression model in R

train(form = criterion ~ .,
      data = data_train,
      method = "glmnet",
      trControl = ctrl,
      tuneGrid = expand.grid(alpha = 1, # Lasso penalty
                              lambda = 1:100)) # Lambda
```

]


---

.pull-left45[

# K-Fold Cross-Validation

### What is it?

Cross-validation is a sampling procedure performed on training data used to &lt;high&gt;estimate a model's prediction performance&lt;/high&gt; in future test data, and to determine &lt;high&gt;optimal tuning parameters&lt;/high&gt; selected to minimize prediction error.

Cross-validation is not "cheating: because it is only performed on the training data (never on the true test dataset)

After cross-validation is complete, the model is trained on the entire dataset, using optimal tuning parameters, resulting in a &lt;high&gt;final model&lt;/high&gt; which can be used for future model testing.

]

.pull-right5[
&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;

### Cross Validation

&lt;img src="image/crossvalidation_4fold.png" width="888" style="display: block; margin: auto;" /&gt;

]

---

.pull-left45[

# K-Fold Cross-Validation

### Steps

1) Split the original training data into K 'folds' (mutually exclusive groups of cases)

2) Select K - 1 folds for training, and 1 fold for testing.

3) Fit the model to the K - 1 training folds, and evaluate its testing accuracy on the test fold.

4) Repeat the process K times, so each fold is used once for testing.

5) Average the model's prediction error across all K folds

]

.pull-right5[
&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;

### Cross Validation

&lt;img src="image/crossvalidation_4fold.png" width="888" style="display: block; margin: auto;" /&gt;

]

---

.pull-left45[

# K-Fold Cross-Validation

### Determining optimal Tuning parameters

By trying different tuning parameters in each iteration, you can determine which value minimises prediction error

Ex) Testing MAE values for values of `cp`



|Fold | cp = .05| cp = .10| &lt;high&gt;cp = .15&lt;/high&gt;| cp = .20|
|:----|--------:|--------:|--------:|--------:|
|1    |     5.13|     4.76|     4.24|     5.38|
|2    |     4.96|     4.54|     4.39|     5.72|
|3    |     5.34|     4.96|     4.13|     6.17|
|4    |     4.76|     5.13|     4.35|     5.20|
|Mean |     5.05|     4.85|     &lt;high&gt;4.28&lt;/high&gt;|     5.62|

Conclusion: `cp = .15` leads to the lowest test MAE

]

.pull-right5[
&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;

### Cross Validation

&lt;img src="image/crossvalidation_4fold.png" width="888" style="display: block; margin: auto;" /&gt;

]

---

# K-Fold Cross-Validation

### Determining optimal Tuning parameters

Once the optimal value of a tuning parameter is determined through cross-validation, the algorithm is fit to the &lt;high&gt;entire training dataset&lt;/high&gt; using the &lt;high&gt;optimal tuning parameter&lt;/high&gt; resulting in the &lt;high&gt;Final Model&lt;/high&gt;

&lt;img src="image/training_final_optimisation.png" width="90%" style="display: block; margin: auto;" /&gt;


---

# Caret





---


# Practical

&lt;font size=6&gt;&lt;b&gt;&lt;a href="https://therbootcamp.github.io/Intro2DataScience_2018Oct/_sessions/Plotting/Plotting_practical.html"&gt;Link to practical&lt;/a&gt;
    </textarea>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false,
"ratio": "16:9"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function() {
  var d = document, s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})();</script>

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
  }
});
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
