<!DOCTYPE html>
<html>
  <head>
    <title>Prediction</title>
    <meta charset="utf-8">
    <meta name="author" content="Applied Machine Learning with R   Basel R Bootcamp" />
    <link href="libs/remark-css/default.css" rel="stylesheet" />
    <link rel="stylesheet" href="baselrbootcamp.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Prediction
### Applied Machine Learning with R<br> <a href='https://therbootcamp.github.io'> Basel R Bootcamp </a> <br> <a href='https://therbootcamp.github.io/appliedML_2019Jan/'> <i class='fas fa-clock' style='font-size:.9em;'></i> </a>  <a href='https://therbootcamp.github.io'> <i class='fas fa-home' style='font-size:.9em;' ></i> </a>  <a href='mailto:therbootcamp@gmail.com'> <i class='fas fa-envelope' style='font-size: .9em;'></i> </a>  <a href='https://www.linkedin.com/company/basel-r-bootcamp/'> <i class='fab fa-linkedin' style='font-size: .9em;'></i> </a>
### January 2019

---


layout: true

&lt;div class="my-footer"&gt;
  &lt;span style="text-align:center"&gt;
    &lt;span&gt; 
      &lt;img src="https://raw.githubusercontent.com/therbootcamp/therbootcamp.github.io/master/_sessions/_image/by-sa.png" height=14 style="vertical-align: middle"/&gt;
    &lt;/span&gt;
    &lt;a href="https://therbootcamp.github.io/"&gt;
      &lt;span style="padding-left:82px"&gt; 
        &lt;font color="#7E7E7E"&gt;
          www.therbootcamp.com
        &lt;/font&gt;
      &lt;/span&gt;
    &lt;/a&gt;
    &lt;a href="https://therbootcamp.github.io/"&gt;
      &lt;font color="#7E7E7E"&gt;
       Applied Machine Learning with R | January 2019
      &lt;/font&gt;
    &lt;/a&gt;
    &lt;/span&gt;
  &lt;/div&gt; 

---







# Prediction is...

&lt;br&gt;&lt;br&gt;
&lt;i&gt;"Prediction is very difficult, especially if it's about the future."&lt;/i&gt;

Nils Bohr, Nobel Laureate in Physics

&lt;br&gt;

&lt;i&gt;"An economist is an expert who will know tomorrow why the things he predicted yesterday didn't happen today."&lt;/i&gt;

Evan Esar

&lt;br&gt;

&lt;i&gt;"Forecasting [prediction] is the art of saying what will happen, and then explaining why it didn't!"&lt;/i&gt;

Anonymous

---

&lt;br&gt;&lt;br&gt;
&lt;div class="figure" style="text-align: center"&gt;
&lt;img src="https://cdn-images-1.medium.com/max/1600/1*_QGyIwpgq831xI54cIe_GQ.jpeg" alt="Source: Medium.com" width="100%" /&gt;
&lt;p class="caption"&gt;Source: Medium.com&lt;/p&gt;
&lt;/div&gt;

---
class: middle, center

# What is model prediction?

&lt;font size = 5&gt;Model prediction (aka, testing) is the process of computing a model's predictions on &lt;i&gt;new&lt;/i&gt; &lt;high&gt;test data&lt;/high&gt;.&lt;/font&gt;

&lt;br&gt;&lt;br&gt;

# What is test data? 

&lt;font size = 5&gt;Test data is a separate, &lt;high&gt;'hold-out' data&lt;/high&gt; set that the model &lt;high&gt;never saw during training&lt;/high&gt;&lt;/font&gt;

---

# Model Training

&lt;img src="image/model_training_flow.png" width="1442" style="display: block; margin: auto;" /&gt;

---
# Model Testing


&lt;img src="image/model_testing_flow.png" width="1439" style="display: block; margin: auto;" /&gt;


---

# Why do we separate training from testing?

.pull-left35[
&lt;br&gt;
Just because a model can &lt;high&gt;fit past data well&lt;/high&gt; (high training accuracy), does &lt;i&gt;not&lt;/i&gt; necessarily mean that it will &lt;high&gt;predict new data well&lt;/high&gt; (high testing accuracy).

&lt;br&gt;&lt;br&gt;

&lt;p align="center"&gt;&lt;i&gt;"An economist is an expert who will know tomorrow why the things he predicted yesterday didn't happen today."&lt;/i&gt;&lt;/p&gt;
&lt;p align="right"&gt;
Evan Esar
&lt;/p&gt;

]
 
.pull-right6[

&lt;p align="center"&gt;
  &lt;img src="https://raw.githubusercontent.com/therbootcamp/Erfurt_2018June/master/_sessions/_image/prediction_collage.png" height=400px&gt;
&lt;/p&gt;


]

---
&lt;br&gt;&lt;br&gt;&lt;br&gt;
&lt;p align = "center"&gt;&lt;font size = 6&gt;&lt;i&gt;"Can you come up with a model that will perfectly fit the training criterion but is worthless in predicting test data?"&lt;/i&gt;&lt;/font&gt;&lt;br&gt;&lt;br&gt;

.pull-left45[


&lt;high&gt;Training data&lt;/high&gt;
&lt;br&gt;


| id|sex | age|fam_history |smoking | criterion|
|--:|:---|---:|:-----------|:-------|---------:|
|  1|m   |  45|No          |FALSE   |         0|
|  2|m   |  43|Yes         |FALSE   |         1|
|  3|f   |  40|Yes         |FALSE   |         1|
|  4|m   |  51|Yes         |FALSE   |         1|
|  5|m   |  44|No          |TRUE    |         0|

]

.pull-right45[


&lt;high&gt; Test data&lt;/high&gt;
&lt;br&gt;


| id|sex | age|fam_history |smoking |criterion |
|--:|:---|---:|:-----------|:-------|:---------|
| 91|m   |  51|Yes         |TRUE    |?         |
| 92|f   |  47|No          |TRUE    |?         |
| 93|m   |  39|No          |TRUE    |?         |
| 94|f   |  51|Yes         |TRUE    |?         |
| 95|f   |  50|Yes         |FALSE   |?         |

]



---


.pull-left4[
&lt;br&gt;&lt;br&gt;&lt;br&gt;

# Overfitting

When a model is consistently &lt;high&gt;less accurate in predicting future data&lt;/high&gt; than in &lt;high&gt;fitting training data&lt;/high&gt;, this is called &lt;high&gt;overfitting&lt;/high&gt;

Overfitting typically occurs when a model 'mistakes' random noise for a predictable signal

]


.pull-right55[
&lt;br&gt;&lt;br&gt;&lt;br&gt;
&lt;div class="figure" style="text-align: center"&gt;
&lt;img src="https://cdn-images-1.medium.com/max/1600/1*SBUK2QEfCP-zvJmKm14wGQ.png" alt="&amp;lt;font size = 3&amp;gt;hackernoon.com&amp;lt;/font&amp;gt;"  /&gt;
&lt;p class="caption"&gt;&lt;font size = 3&gt;hackernoon.com&lt;/font&gt;&lt;/p&gt;
&lt;/div&gt;

&lt;div class="figure" style="text-align: center"&gt;
&lt;img src="https://cdn-images-1.medium.com/max/1200/1*cdvfzvpkJkUudDEryFtCnA.png" alt="&amp;lt;font size = 3&amp;gt;Medium.com&amp;lt;/font&amp;gt;" width="90%" /&gt;
&lt;p class="caption"&gt;&lt;font size = 3&gt;Medium.com&lt;/font&gt;&lt;/p&gt;
&lt;/div&gt;


]


---

# Overfitting

&lt;img src="Prediction_files/figure-html/unnamed-chunk-9-1.png" style="display: block; margin: auto;" /&gt;



---

# Overfitting

.pull-left45[

### How do we account for overfitting?

Always evaluate models based on their performance on new, unseen test data

*Never evaluate models based only on training accuracy!*

Use models with &lt;high&gt;regularization&lt;/high&gt; terms, which explicitly punish models for being too complex.

Use fitting methods such as &lt;high&gt;cross-validation&lt;/high&gt; to find optimal regularization values.

We will learn about these methods in a future session!

]

.pull-right5[

&lt;img src="Prediction_files/figure-html/unnamed-chunk-10-1.png" style="display: block; margin: auto;" /&gt;


]




---

# How do I get separate training and test data?

.pull-left5[

If you don't have two naturally occurring distinct training and test dataset, you can &lt;high&gt;randomly split&lt;/high&gt; a dataset into an &lt;high&gt;X% training&lt;/high&gt; set and &lt;high&gt;1-X% testing&lt;/high&gt; set.

The `caret` function `createDataPartition()` helps you do this automatically.

&lt;u&gt;Natural examples&lt;/u&gt;

|Domain|Training|Test|
|:-------|:------|:------|
|Stock prediction|2017 Trends | 2019 Trends|
|Medical diagnosis| Patients from Hospital A| Patients from Hospital B|
|Crime rates|Statistics from City X|Statistics from City Y|



]

.pull-right45[


&lt;img src="image/train_test_split.png" width="88%" style="display: block; margin: auto;" /&gt;


]


---
class: center, middle

# Two new models enter the ring...

---
class: center, middle

&lt;font color = "gray"&gt;&lt;h1&gt;Regression&lt;/h1&gt;&lt;/font&gt;

&lt;high&gt;&lt;h1&gt;Decision Trees&lt;/h1&gt;&lt;/high&gt;

&lt;font color = "gray"&gt;&lt;h1&gt;Random Forests&lt;/h1&gt;&lt;/font&gt;


---

# Decision Trees

.pull-left4[

In [decision trees](https://en.wikipedia.org/wiki/Decision_tree), the criterion is modeled as a &lt;high&gt;sequence of logical YES or NO questions&lt;/high&gt;.
&lt;br&gt;&lt;br&gt;

&lt;p align="center"&gt;
  &lt;img src="https://raw.githubusercontent.com/therbootcamp/therbootcamp.github.io/master/_sessions/_image/defaulttree.png" height="250px"&gt;
&lt;/p&gt;

]

.pull-right55[

&lt;high&gt;Grow Decisions Trees&lt;/high&gt; by splitting features that maximize *Node Purity*.
&lt;br&gt;&lt;br&gt;
&lt;img src="image/tree_purity_example.png" width="100%" style="display: block; margin: auto;" /&gt;

]

---

# Decision Trees

.pull-left4[

In [decision trees](https://en.wikipedia.org/wiki/Decision_tree), the criterion is modeled as a &lt;high&gt;sequence of logical YES or NO questions&lt;/high&gt;.
&lt;br&gt;&lt;br&gt;

&lt;p align="center"&gt;
  &lt;img src="https://raw.githubusercontent.com/therbootcamp/therbootcamp.github.io/master/_sessions/_image/defaulttree.png" height="250px"&gt;
&lt;/p&gt;

]

.pull-right55[

&lt;high&gt;Fit a Decision Tree&lt;/high&gt; in `caret` using `method = "rpart"`.


```r
# Fit a decision tree with a defined cp = .10

train(form = income ~ .,
      data = baselers,
      method = "rpart",  # Decision Tree
      trControl = ctrl,
      tuneGrid = expand.grid(cp = .10)) # cp
```


]


---

# Decision Trees

.pull-left45[

### Complexity Parameter

Decision trees have a &lt;high&gt;complexity parameter&lt;/high&gt; called `cp`.

The `cp` parameter controls how complex (i.e.; large) trees are allowed to grow

- &lt;high&gt;Small&lt;/high&gt; cp (&lt; 0.01) = &lt;high&gt;Complex&lt;/high&gt; Trees
- &lt;high&gt;Large&lt;/high&gt; cp (&gt; 0.10) = &lt;high&gt;Simple&lt;/high&gt; Trees

There is no "one" best value of `cp` -- the best value of cp depends on your needs and your dataset!

]


.pull-right5[

&lt;img src="image/complexity_parameter.png" width="100%" style="display: block; margin: auto;" /&gt;

]


---

# Decision Trees

.pull-left45[
### Complexity Parameter

Decision trees have a &lt;high&gt;complexity parameter&lt;/high&gt; called `cp`.

The `cp` parameter controls how complex (i.e.; large) trees are allowed to grow

- &lt;high&gt;Small&lt;/high&gt; cp (&lt; 0.01) = &lt;high&gt;Complex&lt;/high&gt; Trees
- &lt;high&gt;Large&lt;/high&gt; cp (&gt; 0.10) = &lt;high&gt;Simple&lt;/high&gt; Trees

There is no "one" best value of `cp` -- the best value of cp depends on your needs and your dataset!


]

.pull-right5[

### Decision Trees in Caret: rpart

When fitting a decision tree, the `cp` parameter can be defined by the user in the `tuneGrid` argument:


```r
# Fit a decision tree with a defined cp = .10

train(form = income ~ .,
      data = baselers,
      method = "rpart",  # Decision Tree
      trControl = ctrl,
      tuneGrid = expand.grid(cp = .10)) # cp
```

- `cp` can also be optimally determined through methods such as &lt;high&gt;cross-validation&lt;/high&gt;, which we will learn later

]


---
class: center, middle

&lt;font color = "gray"&gt;&lt;h1&gt;Regression&lt;/h1&gt;&lt;/font&gt;

&lt;font color = "gray"&gt;&lt;h1&gt;Decision Trees&lt;/h1&gt;&lt;/font&gt;

&lt;high&gt;&lt;h1&gt;Random Forests&lt;/h1&gt;&lt;/high&gt;

---

# Random Forest

.pull-left4[

In [Random Forest](https://en.wikipedia.org/wiki/Random_forest), the criterion is modeled as the &lt;high&gt;aggregate prediction of a large number of decision trees&lt;/high&gt; each based on different features.
&lt;br&gt;

&lt;p align="center"&gt;
  &lt;img src="https://raw.githubusercontent.com/therbootcamp/Erfurt_2018June/master/_sessions/_image/randomforest_diagram.png" height="285px"&gt;&lt;br&gt;
  &lt;a href="https://medium.com/@williamkoehrsen"&gt;Source&lt;/a&gt;
&lt;/p&gt;

]

.pull-right55[

In Random Forests, we create a large set of &lt;high&gt;diverse trees&lt;/high&gt; that can be aggregated into one &lt;high&gt;Wisdom of Crowds&lt;/high&gt; judgment.

&lt;img src="image/tree_crowd.png" width="80%" style="display: block; margin: auto;" /&gt;

]


---

# Random Forest

.pull-left4[

In [Random Forest](https://en.wikipedia.org/wiki/Random_forest), the criterion is modeled as the &lt;high&gt;aggregate prediction of a large number of decision trees&lt;/high&gt; each based on different features.
&lt;br&gt;

&lt;p align="center"&gt;
  &lt;img src="https://raw.githubusercontent.com/therbootcamp/Erfurt_2018June/master/_sessions/_image/randomforest_diagram.png" height="285px"&gt;&lt;br&gt;
  &lt;a href="https://medium.com/@williamkoehrsen"&gt;Source&lt;/a&gt;
&lt;/p&gt;

]

.pull-right55[

To &lt;high&gt;fit a random forest&lt;/high&gt; in caret, use `method = "rf"`.


```r
# Fit a random forest with a defined mtry = 3

train(form = income ~ .,
      data = baselers,
      method = "rf",  # Random Forest
      trControl = ctrl,
      tuneGrid = expand.grid(mtry = 3))
```

]

---

# Random Forest

.pull-left4[

### Diversity Parameter: mtry

Random Forests have a &lt;high&gt;diversity parameter&lt;/high&gt; called &lt;high&gt;mtry&lt;/high&gt;

Technically, this controls how many features are randomly considered at each split of the trees

- Small mtry (~ 1) = Diverse Forest
- Large mtry (&gt; 5) = Similar Forest

There is no "one" best value of `mtry` -- the best value of `mtry` depends on your needs and your dataset!

]

.pull-right55[

&lt;img src="image/mtry_parameter.png" width="90%" style="display: block; margin: auto;" /&gt;

]

---

# Random Forest

.pull-left4[

### Diversity Parameter: mtry

Random Forests have a &lt;high&gt;diversity parameter&lt;/high&gt; called &lt;high&gt;mtry&lt;/high&gt;

Technically, this controls how many features are randomly considered at each split of the trees

- Small mtry (~ 1) = Diverse Forest
- Large mtry (&gt; 5) = Similar Forest

There is no "one" best value of `mtry` -- the best value of `mtry` depends on your needs and your dataset!

]

.pull-right55[

When fitting a random forest, the `mtry` parameter can be defined by the user in the `tuneGrid` argument.


```r
# Fit a random forest with a defined mtry = 2

train(form = income ~ .,
      data = baselers,
      method = "rpart",  # Decision Tree
      trControl = ctrl,
      tuneGrid = expand.grid(mtry = 2)) # mtry
```

- `mtry` can also be optimally determined through methods such as &lt;high&gt;cross-validation&lt;/high&gt;, which we will learn later

]

---
class: center,  middle

&lt;br&gt;&lt;br&gt;

# Evaluating model predictions with caret

&lt;img src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2014/09/Caret-package-in-R.png" width="70%" style="display: block; margin: auto;" /&gt;






---

# Predict new data with predict()

.pull-left45[

To &lt;high&gt;test model predictions&lt;/high&gt; with `caret`, all you need to do is get a vector of predictions from a new dataframe `newdata` using the `predict()` function:


```r
# Get predictions for test data!
predict(mod, newdata = data_test)
```

&lt;br&gt;

|argument|description|
|:----|:-----|
|object| A machine learning / statistical object created from `caret`, ...|
|newdata|A dataframe of new data|

This returns a vector of predicted values for your new data!


]

.pull-right5[

&lt;high&gt;Get predictions&lt;/high&gt;, use `predict(mod, newdata = data_test)`


```r
# Load training and test data
data_train &lt;- read_csv("1_Data/XXX_train.csv")
data_test &lt;- read_csv("1_Data/XXX_test.csv")

# Fit model to training data
mod &lt;- train(form = Y ~ .,
             method = "glm",
             data = data_train)

# Get fitted values (for training data)
mod_fit &lt;- predict(mod)

# Predictions for NEW data_test data!
mod_pred &lt;- predict(mod, newdata = data_test)
```


]


---

# Predict new data with predict()

.pull-left45[

To &lt;high&gt;test model predictions&lt;/high&gt; with `caret`, all you need to do is get a vector of predictions from a new dataframe `newdata` using the `predict()` function:


```r
# Get predictions for test data!
predict(mod, newdata = data_test)
```

|argument|description|
|:----|:-----|
|object| A machine learning / statistical object created from `caret`, ...|
|newdata|A dataframe of new data|

This returns a vector of predicted values for your new data!

]

.pull-right5[

Compare predictions to the criterion with `postResample()`


```r
# Define criterion
criterion_train &lt;- data_train$Y
criterion_test &lt;- data_test$Y

# Fitting performance
postResample(pred = mod_fit, 
             obs = criterion_train)

#    RMSE Rsquared      MAE 
#2.454015 0.848482 1.889584 

# Prediction performance
postResample(pred = mod_pred, 
             obs = criterion_test)

#     RMSE  Rsquared       MAE 
#3.4763941 0.6977009 2.6764346 
```


]

---


# Split data with createDataPartition()

.pull-left4[

Use `createDataPartition()` to &lt;high&gt;split a dataset&lt;/high&gt; into separate training and test datasets




```r
# Create a set of indices for random 
# selection of 70% of data

createDataPartition(y = data$Y
                    p = .7,
                    list = FALSE)
```

|Argument|Description|
|:----|:-----|
|y| The criterion|
|p|Percent of data to select|

This returns a vector of indices you can then use to select rows (see right)

]

.pull-right55[

Create separate `XX_train` and `data_test` datasets from a single 'large' dataset


```r
# Set the randomisation seed to get the 
#  same results each time
set.seed(100)

# Get indices for training
index &lt;- createDataPartition(y = baselers$income,
                             p = .7,
                             list = FALSE)

# Create training data
baselers_train &lt;- baselers %&gt;% 
  slice(index)

# Create test data
baselers_test &lt;- baselers %&gt;% 
  slice(-index)
```


]





---
.pull-left5[

# 5 steps with caret

Step 0: Load training and test data (or create with `createDataPartition()`)


```r
data_train &lt;- read_csv("1_Data/XXX_train.csv")
data_test &lt;- read_csv("1_Data/XXX_test.csv")
```

Step 1: Define control parameters


```r
# Use method = "none" for no advanced fitting
ctrl &lt;- trainControl(method = "none")
```

Step 2: Train model


```r
mod &lt;- train(form = Y ~ .,  
             data = data_train,
             method = "My Favorite Model",
             trControl = ctrl,
             tuneGrid = expand.grid(mtry = 2))
```

]

.pull-right45[
&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;
Step 3: Explore


```r
mod            # Print object
mod$finalModel # Final model
```

Step 4: Predict 


```r
rpart_pred &lt;- predict(object = mod, 
                      newdata = data_test)
```

Step 5: Evaluate prediction accuracy


```r
postResample(pred = rpart_pred, 
             obs = data_test$Y)
```

]

---
class: middle, center

&lt;h1&gt; Questions?&lt;/h1&gt;


&lt;h1&gt;&lt;a href=https://therbootcamp.github.io/appliedML_2019Jan/_sessions/Prediction/Prediction_practical.html&gt;Practical&lt;/a&gt;&lt;/h1&gt;
    </textarea>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false,
"ratio": "16:9"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function() {
  var d = document, s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})();</script>

<script>
(function() {
  var i, text, code, codes = document.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
})();
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
