<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />




<title>Prediction</title>

<script src="Prediction_practical_files/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="Prediction_practical_files/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="Prediction_practical_files/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="Prediction_practical_files/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="Prediction_practical_files/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="Prediction_practical_files/navigation-1.1/tabsets.js"></script>
<link href="Prediction_practical_files/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="Prediction_practical_files/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>

<link rel="stylesheet" href="practical.css" type="text/css" />

</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>



<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->






<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Prediction</h1>
<h4 class="author"><em><table style='table-layout:fixed;width:100%;border:0;padding:0;margin:0'>
<col width='10%'>
<col width='10%'>
<tr style="border:none">
<td style="display:block;width:100%;text-align:left;vertical-align:bottom;padding:0;margin:0;border:none" nowrap>
<font style='font-style:normal'>Applied Machine Learning with R</font> <br> <a href='https://therbootcamp.github.io/appliedML_2019Jan/'> <i class='fas fa-clock' style='font-size:.9em;' ></i> </a> <a href='https://therbootcamp.github.io'> <i class='fas fa-home' style='font-size:.9em;'></i> </a> <a href='mailto:therbootcamp@gmail.com'> <i class='fas fa-envelope' style='font-size: .9em;'></i> </a> <a href='https://www.linkedin.com/company/basel-r-bootcamp/'> <i class='fab fa-linkedin' style='font-size: .9em;'></i> </a> <a href='https://therbootcamp.github.io'> <font style='font-style:normal'>Basel R Bootcamp</font> </a>  
</td>
<td style="width:100%;vertical-align:bottom;text-align:right;padding:0;margin:0;border:none">
<img src='https://raw.githubusercontent.com/therbootcamp/therbootcamp.github.io/master/_sessions/_image/by-sa.png' style='height:15px;width:80px'/>
</td>
</tr>
</table></em></h4>

</div>


<p align="center">
<img width="100%" src="https://cdn-images-1.medium.com/max/1200/0*F0y1bmOEzCFCcPE_" margin=0><br> <font style="font-size:10px">from <a href="https://Medium.com/">Medium.com</a></font>
</p>
<div id="section" class="section level2 tabset">
<h2></h2>
<div id="overview" class="section level3">
<h3>Overview</h3>
<p>By the end of this practical you will know how to:</p>
<ol style="list-style-type: decimal">
<li>Fit regression, decision trees and random forests to training data</li>
<li>Evaluate model fitting <em>and</em> prediction performance in a test set</li>
<li>Compare the fitting and prediction performance of two models</li>
<li>Explore the effects of features on model predictions</li>
</ol>
</div>
<div id="datasets" class="section level3">
<h3>Datasets</h3>
<table>
<thead>
<tr class="header">
<th align="left">File</th>
<th align="left">Rows</th>
<th align="left">Columns</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><a href="https://raw.githubusercontent.com/therbootcamp/appliedML_2019Jan/master/1_Data/college_train.csv">college_train.csv</a></td>
<td align="left">500</td>
<td align="left">18</td>
</tr>
<tr class="even">
<td align="left"><a href="https://raw.githubusercontent.com/therbootcamp/appliedML_2019Jan/master/1_Data/college_est.csv">college_test.csv</a></td>
<td align="left">277</td>
<td align="left">18</td>
</tr>
<tr class="odd">
<td align="left"><a href="https://raw.githubusercontent.com/therbootcamp/appliedML_2019Jan/master/1_Data/house_train.csv">house_train.csv</a></td>
<td align="left">5000</td>
<td align="left">21</td>
</tr>
<tr class="even">
<td align="left"><a href="https://raw.githubusercontent.com/therbootcamp/appliedML_2019Jan/master/1_Data/_data/house_test.csv">house_test.csv</a></td>
<td align="left">1000</td>
<td align="left">21</td>
</tr>
</tbody>
</table>
<ul>
<li>The <code>college_train</code> and <code>college_test</code> data are taken from the <code>College</code> dataset in the <code>ISLR</code> package. To see column descriptions, run the following:</li>
</ul>
<pre class="r"><code>library(ISLR)   # Load ISLR package
?College        # Look at help menu for College</code></pre>
<ul>
<li>The <code>carseats_train</code> and <code>carseats_test</code> data are taken from the <code>Carseats</code> dataset in the <code>ISLR</code> package. To see column descriptions, run the following:</li>
</ul>
<pre class="r"><code>library(ISLR)   # Load ISLR package
?Carseats        # Look at help menu for Carseats</code></pre>
<ul>
<li>The <code>house_train</code> and <code>house_test</code> data come from <a href="https://www.kaggle.com/harlfoxem/housesalesprediction" class="uri">https://www.kaggle.com/harlfoxem/housesalesprediction</a></li>
</ul>
</div>
<div id="glossary" class="section level3">
<h3>Glossary</h3>
<table style="width:83%;">
<colgroup>
<col width="6%" />
<col width="11%" />
<col width="65%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Function</th>
<th align="left">Package</th>
<th align="left">Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><code>trainControl()</code></td>
<td align="left"><code>caret</code></td>
<td align="left">Define modelling control parameters</td>
</tr>
<tr class="even">
<td align="left"><code>train()</code></td>
<td align="left"><code>caret</code></td>
<td align="left">Train a model</td>
</tr>
<tr class="odd">
<td align="left"><code>predict(object, newdata)</code></td>
<td align="left"><code>stats</code></td>
<td align="left">Predict the criterion values of <code>newdata</code> based on <code>object</code></td>
</tr>
<tr class="even">
<td align="left"><code>postResample()</code></td>
<td align="left"><code>caret</code></td>
<td align="left">Calculate aggregate model performance in regression tasks</td>
</tr>
<tr class="odd">
<td align="left"><code>confusionMatrix()</code></td>
<td align="left"><code>caret</code></td>
<td align="left">Calculate aggregate model performance in classification tasks</td>
</tr>
</tbody>
</table>
</div>
<div id="packages" class="section level3">
<h3>Packages</h3>
<table>
<thead>
<tr class="header">
<th align="left">Package</th>
<th align="left">Installation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><code>tidyverse</code></td>
<td align="left"><code>install.packages(&quot;tidyverse&quot;)</code></td>
</tr>
<tr class="even">
<td align="left"><code>caret</code></td>
<td align="left"><code>install.packages(&quot;caret&quot;)</code></td>
</tr>
<tr class="odd">
<td align="left"><code>partykit</code></td>
<td align="left"><code>install.packages(&quot;partykit&quot;)</code></td>
</tr>
<tr class="even">
<td align="left"><code>party</code></td>
<td align="left"><code>install.packages(&quot;party&quot;)</code></td>
</tr>
</tbody>
</table>
</div>
<div id="cheatsheet" class="section level3">
<h3>Cheatsheet</h3>
<figure>
<center>
<a href="https://github.com/rstudio/cheatsheets/raw/master/caret.pdf"> <img src="https://www.rstudio.com/wp-content/uploads/2015/01/caret-cheatsheet.png" alt="Trulli" style="width:70%">
<figcaption>
hhttps://github.com/rstudio/cheatsheets/raw/master/caret.pdf
</figcaption>
</a>
</figure>
</div>
<div id="examples" class="section level3">
<h3>Examples</h3>
<pre class="r"><code># Fitting and evaluating regression, decision trees, and random forests

# Step 0: Load packages-----------

library(tidyverse)    # Load tidyverse for dplyr and tidyr
library(caret)        # For ML mastery 
library(partykit)     # For decision trees
library(party)        # For decision trees

# Step 1: Load and Clean, and Explore Training data ----------------------

# training data
data_train &lt;- read_csv(&quot;1_Data/mpg_train.csv&quot;)

# test data
data_test &lt;- read_csv(&quot;1_Data/mpg_test.csv&quot;)

# Convert all characters to factor
#  Some ML models require factors

data_train &lt;- data_train %&gt;%
  mutate_if(is.character, factor)

data_test &lt;- data_test %&gt;%
  mutate_if(is.character, factor)

# Explore training data

data_train        # Print the dataset
View(data_train)  # Open in a new spreadsheet-like window 
dim(data_train)   # Print dimensions
names(data_train) # Print the names

# Define criterion_train
#   We&#39;ll use this later to evaluate model accuracy

criterion_train &lt;- data_train$hwy

# Step 2: Define training control parameters -------------

# In this case, I will set method = &quot;none&quot; to fit to 
#  the entire dataset without any fancy methods

ctrl_none &lt;- trainControl(method = &quot;none&quot;) 

# Step 3: Train model: -----------------------------
#   Criterion: hwy
#   Features: year, cyl, displ

# Regression --------------------------

hwy_glm &lt;- train(form = hwy ~ year + cyl + displ,
                 data = data_train,
                 method = &quot;glm&quot;,
                 trControl = ctrl_none)

# Look at summary information
hwy_glm$finalModel
summary(hwy_glm)

# Save fitted values
glm_fit &lt;- predict(hwy_glm)

#  Calculate fitting accuracies
postResample(pred = glm_fit, 
             obs = criterion_train)

# Decision Trees ----------------

hwy_rpart &lt;- train(form = hwy ~ year + cyl + displ,
                data = data_train,
                method = &quot;rpart&quot;,
                trControl = ctrl_none,
                tuneGrid = expand.grid(cp = .01))   # Set complexity parameter

# Look at summary information
hwy_rpart$finalModel
plot(as.party(hwy_rpart$finalModel))   # Visualise your trees

# Save fitted values
rpart_predfit &lt;- predict(hwy_rpart)

# Calculate fitting accuracies
postResample(pred = rpart_predfit, obs = criterion_train)

# Random Forests -------------------------

hwy_rf &lt;- train(form = hwy ~ year + cyl + displ,
                data = data_train,
                method = &quot;rf&quot;,
                trControl = ctrl_none,
                tuneGrid = expand.grid(mtry = 2))   # Set number of features randomly selected

# Look at summary information
hwy_rf$finalModel

# Save fitted values
rf_fit &lt;- predict(hwy_rf)

# Calculate fitting accuracies
postResample(pred = rf_fit, obs = criterion_train)

# Visualise Accuracy -------------------------

# Tidy competition results
accuracy &lt;- tibble(criterion_train = criterion_train,
                   Regression = glm_fit,
                   DecisionTrees = rpart_predfit,
                   RandomForest = rf_fit) %&gt;%
               gather(model, prediction, -criterion_train) %&gt;%
  
  # Add error measures
  mutate(se = prediction - criterion_train,
         ae = abs(prediction - criterion_train))

# Calculate summaries
accuracy_agg &lt;- accuracy %&gt;%
                  group_by(model) %&gt;%
                  summarise(mae = mean(ae))   # Calculate MAE (mean absolute error)

# Plot A) Scatterplot of truth versus predictions

ggplot(data = accuracy,
       aes(x = criterion_train, y = prediction, col = model)) +
  geom_point(alpha = .5) +
  geom_abline(slope = 1, intercept = 0) +
  labs(title = &quot;Predicting mpg$hwy&quot;,
       subtitle = &quot;Black line indicates perfect performance&quot;)

# Plot B) Violin plot of absolute errors

ggplot(data = accuracy, 
       aes(x = model, y = ae, fill = model)) + 
  geom_violin() + 
  geom_jitter(width = .05, alpha = .2) +
  labs(title = &quot;Fitting Absolute Errors&quot;,
       subtitle = &quot;Numbers indicate means&quot;,
       x = &quot;Model&quot;,
       y = &quot;Absolute Error&quot;) +
  guides(fill = FALSE) +
  annotate(geom = &quot;label&quot;, 
           x = accuracy_agg$model, 
           y = accuracy_agg$mae, 
           label = round(accuracy_agg$mae, 2))

# Step 5: Access prediction ------------------------------

# Define criterion_train
criterion_test &lt;- data_test$hwy

# Save predicted values
glm_pred &lt;- predict(hwy_glm, newdata = data_test)
rpart_pred &lt;- predict(hwy_rpart, newdata = data_test)
rf_pred &lt;- predict(hwy_rf, newdata = data_test)

#  Calculate fitting accuracies
postResample(pred = glm_pred, obs = criterion_test)
postResample(pred = rpart_pred, obs = criterion_test)
postResample(pred = rf_pred, obs = criterion_test)

# Visualise Accuracy -------------------------

# Tidy competition results
accuracy &lt;- tibble(criterion_test = criterion_test,
                   Regression = glm_pred,
                   DecisionTrees = rpart_pred,
                   RandomForest = rf_pred) %&gt;%
               gather(model, prediction, -criterion_test) %&gt;%
  
  # Add error measures
  mutate(se = prediction - criterion_test,
         ae = abs(prediction - criterion_test))

# Calculate summaries
accuracy_agg &lt;- accuracy %&gt;%
                  group_by(model) %&gt;%
                  summarise(mae = mean(ae))   # Calculate MAE (mean absolute error)

# Plot A) Scatterplot of truth versus predictions

ggplot(data = accuracy,
       aes(x = criterion_test, y = prediction, col = model)) +
  geom_point(alpha = .5) +
  geom_abline(slope = 1, intercept = 0) +
  labs(title = &quot;Predicting mpg$hwy&quot;,
       subtitle = &quot;Black line indicates perfect performance&quot;)

# Plot B) Violin plot of absolute errors

ggplot(data = accuracy, 
       aes(x = model, y = ae, fill = model)) + 
  geom_violin() + 
  geom_jitter(width = .05, alpha = .2) +
  labs(title = &quot;Prediction Absolute Errors&quot;,
       subtitle = &quot;Numbers indicate means&quot;,
       x = &quot;Model&quot;,
       y = &quot;Absolute Error&quot;) +
  guides(fill = FALSE) +
  annotate(geom = &quot;label&quot;, 
           x = accuracy_agg$model, 
           y = accuracy_agg$mae, 
           label = round(accuracy_agg$mae, 2))</code></pre>
</div>
</div>
<div id="college-graduation-rates" class="section level1">
<h1>College Graduation Rates</h1>
<p>In this section, we will again predict college graduation rates <code>Grad_Rate</code> from the <code>college_train</code> and <code>college_test</code> datasets. Here’s how the first few rows of <code>college_train</code> should look:</p>
<table>
<thead>
<tr class="header">
<th align="left">Private</th>
<th align="right">Apps</th>
<th align="right">Accept</th>
<th align="right">Enroll</th>
<th align="right">Top10perc</th>
<th align="right">Top25perc</th>
<th align="right">F.Undergrad</th>
<th align="right">P.Undergrad</th>
<th align="right">Outstate</th>
<th align="right">Room.Board</th>
<th align="right">Books</th>
<th align="right">Personal</th>
<th align="right">PhD</th>
<th align="right">Terminal</th>
<th align="right">S.F.Ratio</th>
<th align="right">perc.alumni</th>
<th align="right">Expend</th>
<th align="right">Grad.Rate</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Yes</td>
<td align="right">1202</td>
<td align="right">1054</td>
<td align="right">326</td>
<td align="right">18</td>
<td align="right">44</td>
<td align="right">1410</td>
<td align="right">299</td>
<td align="right">13404</td>
<td align="right">5160</td>
<td align="right">450</td>
<td align="right">1050</td>
<td align="right">78</td>
<td align="right">86</td>
<td align="right">15.6</td>
<td align="right">30</td>
<td align="right">9114</td>
<td align="right">65</td>
</tr>
<tr class="even">
<td align="left">Yes</td>
<td align="right">1415</td>
<td align="right">714</td>
<td align="right">338</td>
<td align="right">18</td>
<td align="right">52</td>
<td align="right">1345</td>
<td align="right">44</td>
<td align="right">5120</td>
<td align="right">3200</td>
<td align="right">500</td>
<td align="right">2140</td>
<td align="right">52</td>
<td align="right">60</td>
<td align="right">18.1</td>
<td align="right">9</td>
<td align="right">3930</td>
<td align="right">69</td>
</tr>
<tr class="odd">
<td align="left">Yes</td>
<td align="right">4778</td>
<td align="right">2767</td>
<td align="right">678</td>
<td align="right">50</td>
<td align="right">89</td>
<td align="right">2587</td>
<td align="right">120</td>
<td align="right">19670</td>
<td align="right">5820</td>
<td align="right">575</td>
<td align="right">1119</td>
<td align="right">77</td>
<td align="right">96</td>
<td align="right">10.1</td>
<td align="right">47</td>
<td align="right">16593</td>
<td align="right">83</td>
</tr>
<tr class="even">
<td align="left">Yes</td>
<td align="right">1220</td>
<td align="right">974</td>
<td align="right">481</td>
<td align="right">28</td>
<td align="right">67</td>
<td align="right">1964</td>
<td align="right">623</td>
<td align="right">7800</td>
<td align="right">3664</td>
<td align="right">650</td>
<td align="right">900</td>
<td align="right">61</td>
<td align="right">61</td>
<td align="right">11.1</td>
<td align="right">19</td>
<td align="right">7614</td>
<td align="right">49</td>
</tr>
<tr class="odd">
<td align="left">Yes</td>
<td align="right">1981</td>
<td align="right">1541</td>
<td align="right">514</td>
<td align="right">18</td>
<td align="right">36</td>
<td align="right">1927</td>
<td align="right">1084</td>
<td align="right">12500</td>
<td align="right">6200</td>
<td align="right">375</td>
<td align="right">1000</td>
<td align="right">73</td>
<td align="right">75</td>
<td align="right">16.8</td>
<td align="right">22</td>
<td align="right">8707</td>
<td align="right">80</td>
</tr>
<tr class="even">
<td align="left">Yes</td>
<td align="right">1217</td>
<td align="right">1088</td>
<td align="right">496</td>
<td align="right">36</td>
<td align="right">69</td>
<td align="right">1773</td>
<td align="right">884</td>
<td align="right">11505</td>
<td align="right">3255</td>
<td align="right">1000</td>
<td align="right">2075</td>
<td align="right">35</td>
<td align="right">46</td>
<td align="right">16.7</td>
<td align="right">23</td>
<td align="right">7140</td>
<td align="right">67</td>
</tr>
<tr class="odd">
<td align="left">No</td>
<td align="right">8579</td>
<td align="right">5561</td>
<td align="right">3681</td>
<td align="right">25</td>
<td align="right">50</td>
<td align="right">17880</td>
<td align="right">1673</td>
<td align="right">6994</td>
<td align="right">3384</td>
<td align="right">700</td>
<td align="right">2681</td>
<td align="right">88</td>
<td align="right">94</td>
<td align="right">13.7</td>
<td align="right">17</td>
<td align="right">9657</td>
<td align="right">57</td>
</tr>
<tr class="even">
<td align="left">No</td>
<td align="right">833</td>
<td align="right">669</td>
<td align="right">279</td>
<td align="right">3</td>
<td align="right">13</td>
<td align="right">1224</td>
<td align="right">345</td>
<td align="right">7656</td>
<td align="right">4690</td>
<td align="right">500</td>
<td align="right">624</td>
<td align="right">80</td>
<td align="right">91</td>
<td align="right">14.4</td>
<td align="right">15</td>
<td align="right">6564</td>
<td align="right">36</td>
</tr>
<tr class="odd">
<td align="left">No</td>
<td align="right">10706</td>
<td align="right">7219</td>
<td align="right">2397</td>
<td align="right">12</td>
<td align="right">37</td>
<td align="right">14826</td>
<td align="right">1979</td>
<td align="right">7799</td>
<td align="right">3296</td>
<td align="right">470</td>
<td align="right">1750</td>
<td align="right">73</td>
<td align="right">78</td>
<td align="right">17.3</td>
<td align="right">11</td>
<td align="right">6086</td>
<td align="right">56</td>
</tr>
<tr class="even">
<td align="left">Yes</td>
<td align="right">938</td>
<td align="right">864</td>
<td align="right">511</td>
<td align="right">29</td>
<td align="right">62</td>
<td align="right">1715</td>
<td align="right">103</td>
<td align="right">12247</td>
<td align="right">4221</td>
<td align="right">500</td>
<td align="right">600</td>
<td align="right">70</td>
<td align="right">88</td>
<td align="right">13.1</td>
<td align="right">26</td>
<td align="right">8847</td>
<td align="right">72</td>
</tr>
</tbody>
</table>
<div id="a---setup" class="section level2">
<h2>A - Setup</h2>
<ol style="list-style-type: decimal">
<li><p>Open your <code>BaselRBootcamp</code> R project. It should already have the folders <code>1_Data</code> and <code>2_Code</code>. Make sure that the data file(s) listed in the <code>Datasets</code> section above are in your <code>1_Data</code> folder</p></li>
<li>Open a new R script. At the top of the script, using comments, write your name and the date. Save it as a new file called <code>Prediction_College_practical.R</code> in the <code>2_Code</code> folder.<br />
</li>
<li><p>Using <code>library()</code> load the set of packages for this practical listed in the packages section above.</p></li>
</ol>
<pre class="r"><code>## NAME
## DATE
## Prediction Practical - With regression, decision trees, and random forests

library(tidyverse)
library(caret)
library(party)
library(partykit)</code></pre>
<ol start="4" style="list-style-type: decimal">
<li>Run the code below to load each of the datasets listed in the <code>Datasets</code> as new objects</li>
</ol>
<pre class="r"><code># College data
college_train &lt;- read_csv(file = &quot;1_Data/college_train.csv&quot;)
college_test &lt;- read_csv(file = &quot;1_Data/college_test.csv&quot;)</code></pre>
<ol start="5" style="list-style-type: decimal">
<li>Take a look at the first few rows of each dataframe by printing them to the console.</li>
</ol>
<pre class="r"><code># Print dataframes to the console

college_train</code></pre>
<pre><code># A tibble: 500 x 18
   Private  Apps Accept Enroll Top10perc Top25perc F.Undergrad P.Undergrad
   &lt;chr&gt;   &lt;int&gt;  &lt;int&gt;  &lt;int&gt;     &lt;int&gt;     &lt;int&gt;       &lt;int&gt;       &lt;int&gt;
 1 Yes      1202   1054    326        18        44        1410         299
 2 Yes      1415    714    338        18        52        1345          44
 3 Yes      4778   2767    678        50        89        2587         120
 4 Yes      1220    974    481        28        67        1964         623
 5 Yes      1981   1541    514        18        36        1927        1084
 6 Yes      1217   1088    496        36        69        1773         884
 7 No       8579   5561   3681        25        50       17880        1673
 8 No        833    669    279         3        13        1224         345
 9 No      10706   7219   2397        12        37       14826        1979
10 Yes       938    864    511        29        62        1715         103
# ... with 490 more rows, and 10 more variables: Outstate &lt;int&gt;,
#   Room.Board &lt;int&gt;, Books &lt;int&gt;, Personal &lt;int&gt;, PhD &lt;int&gt;,
#   Terminal &lt;int&gt;, S.F.Ratio &lt;dbl&gt;, perc.alumni &lt;int&gt;, Expend &lt;int&gt;,
#   Grad.Rate &lt;int&gt;</code></pre>
<pre class="r"><code>college_test</code></pre>
<pre><code># A tibble: 277 x 18
   Private  Apps Accept Enroll Top10perc Top25perc F.Undergrad P.Undergrad
   &lt;chr&gt;   &lt;int&gt;  &lt;int&gt;  &lt;int&gt;     &lt;int&gt;     &lt;int&gt;       &lt;int&gt;       &lt;int&gt;
 1 No       9251   7333   3076        14        45       13699        1213
 2 Yes      1480   1257    452         6        25        2961         572
 3 No       2336   1725   1043        10        27        5438        4058
 4 Yes      1262   1102    276        14        40         978          98
 5 Yes       959    771    351        23        48        1662         209
 6 Yes       331    331    225        15        36        1100         166
 7 Yes       804    632    281        29        72         840          68
 8 No        285    280    208        21        43        1140         473
 9 Yes       323    278    122        31        51         393           4
10 Yes       504    482    185        10        36         550          84
# ... with 267 more rows, and 10 more variables: Outstate &lt;int&gt;,
#   Room.Board &lt;int&gt;, Books &lt;int&gt;, Personal &lt;int&gt;, PhD &lt;int&gt;,
#   Terminal &lt;int&gt;, S.F.Ratio &lt;dbl&gt;, perc.alumni &lt;int&gt;, Expend &lt;int&gt;,
#   Grad.Rate &lt;int&gt;</code></pre>
<ol start="6" style="list-style-type: decimal">
<li>Print the numbers of rows and columns of each dataset using the <code>dim()</code> function</li>
</ol>
<pre class="r"><code># Print numbers of rows and columns

dim(XXX)
dim(XXX)</code></pre>
<pre class="r"><code>dim(college_train)</code></pre>
<pre><code>[1] 500  18</code></pre>
<pre class="r"><code>dim(college_test)</code></pre>
<pre><code>[1] 277  18</code></pre>
<ol start="7" style="list-style-type: decimal">
<li>Look at the names of the dataframes with the <code>names()</code> function.</li>
</ol>
<pre class="r"><code># Print the names of each dataframe

names(XXX)
names(XXX)</code></pre>
<pre class="r"><code>names(college_train)</code></pre>
<pre><code> [1] &quot;Private&quot;     &quot;Apps&quot;        &quot;Accept&quot;      &quot;Enroll&quot;      &quot;Top10perc&quot;  
 [6] &quot;Top25perc&quot;   &quot;F.Undergrad&quot; &quot;P.Undergrad&quot; &quot;Outstate&quot;    &quot;Room.Board&quot; 
[11] &quot;Books&quot;       &quot;Personal&quot;    &quot;PhD&quot;         &quot;Terminal&quot;    &quot;S.F.Ratio&quot;  
[16] &quot;perc.alumni&quot; &quot;Expend&quot;      &quot;Grad.Rate&quot;  </code></pre>
<pre class="r"><code>names(college_test)</code></pre>
<pre><code> [1] &quot;Private&quot;     &quot;Apps&quot;        &quot;Accept&quot;      &quot;Enroll&quot;      &quot;Top10perc&quot;  
 [6] &quot;Top25perc&quot;   &quot;F.Undergrad&quot; &quot;P.Undergrad&quot; &quot;Outstate&quot;    &quot;Room.Board&quot; 
[11] &quot;Books&quot;       &quot;Personal&quot;    &quot;PhD&quot;         &quot;Terminal&quot;    &quot;S.F.Ratio&quot;  
[16] &quot;perc.alumni&quot; &quot;Expend&quot;      &quot;Grad.Rate&quot;  </code></pre>
<ol start="8" style="list-style-type: decimal">
<li>Open each dataset in a new window using <code>View()</code>. Do they look ok?</li>
</ol>
<pre class="r"><code># Open each dataset in a window.

View(XXX)
View(XXX)</code></pre>
<ol start="9" style="list-style-type: decimal">
<li>We need to do a little bit of data cleaning before starting. Specifically, we need to convert all character columns to factors: Do this by running the following code:</li>
</ol>
<pre class="r"><code># Convert all character columns to factor

college_train &lt;- college_train %&gt;%
          mutate_if(is.character, factor)

college_test &lt;- college_test %&gt;%
          mutate_if(is.character, factor)</code></pre>
</div>
<div id="b---fitting" class="section level2">
<h2>B - Fitting</h2>
<p>Your goal in this task is to fit models predicting <code>Grad.Rate</code>, the percentage of attendees who graduate from each college</p>
<ol style="list-style-type: decimal">
<li>Using <code>trainControl()</code>, set your training control method to <code>&quot;none&quot;</code>. Save your object as <code>ctrl_none</code>.</li>
</ol>
<pre class="r"><code># Set training method to &quot;none&quot; for simple fitting
#  Note: This is for demonstration purposes, you would almost
#   never do this for a &#39;real&#39; prediction task!

ctrl_none &lt;- trainControl(method = &quot;XXX&quot;)</code></pre>
<pre class="r"><code>ctrl_none &lt;- trainControl(method = &quot;none&quot;)</code></pre>
<div id="regression" class="section level3">
<h3>Regression</h3>
<ol start="2" style="list-style-type: decimal">
<li>Using <code>train()</code> fit a regression model called <code>grad_glm</code> predicting <code>Grad.Rate</code> as a function of all features</li>
</ol>
<ul>
<li>For the <code>form</code> argument, use <code>Grad.Rate ~ .</code></li>
<li>For the <code>data</code> argument, use <code>college_train</code> in the data argument</li>
<li>For the <code>method</code> argument, use <code>method = &quot;glm&quot;</code> for regression</li>
<li>For the <code>trControl</code> argument, use your <code>ctrl_none</code> object you created before</li>
</ul>
<pre class="r"><code>grad_glm &lt;- train(form = XX ~ .,
                  data = XX,
                  method = &quot;XXX&quot;,
                  trControl = ctrl_none)</code></pre>
<pre class="r"><code>grad_glm &lt;- train(form = Grad.Rate ~ .,
                  data = college_train,
                  method = &quot;glm&quot;,
                  trControl = ctrl_none)</code></pre>
<ol start="3" style="list-style-type: decimal">
<li>Explore your <code>grad_glm</code> object by looking at <code>grad_glm$finalModel</code> and using <code>summary()</code>, what do you find?</li>
</ol>
<pre class="r"><code>grad_glm$XXX
summary(XXX)</code></pre>
<pre class="r"><code>grad_glm$finalModel</code></pre>
<pre><code>
Call:  NULL

Coefficients:
(Intercept)   PrivateYes         Apps       Accept       Enroll  
  31.010972     1.701840     0.001926    -0.001754     0.005550  
  Top10perc    Top25perc  F.Undergrad  P.Undergrad     Outstate  
  -0.049727     0.206252    -0.001069    -0.001294     0.001782  
 Room.Board        Books     Personal          PhD     Terminal  
   0.000871    -0.000932    -0.001457     0.104743    -0.101789  
  S.F.Ratio  perc.alumni       Expend  
   0.275943     0.219944    -0.000683  

Degrees of Freedom: 499 Total (i.e. Null);  482 Residual
Null Deviance:      142000 
Residual Deviance: 74600    AIC: 3960</code></pre>
<pre class="r"><code>summary(grad_glm)</code></pre>
<pre><code>
Call:
NULL

Deviance Residuals: 
   Min      1Q  Median      3Q     Max  
-38.10   -7.24   -0.58    7.51   47.10  

Coefficients:
             Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept) 31.010972   5.911481    5.25  2.3e-07 ***
PrivateYes   1.701840   2.114677    0.80  0.42135    
Apps         0.001926   0.000572    3.37  0.00082 ***
Accept      -0.001754   0.001046   -1.68  0.09417 .  
Enroll       0.005550   0.002872    1.93  0.05387 .  
Top10perc   -0.049727   0.086281   -0.58  0.56466    
Top25perc    0.206252   0.066972    3.08  0.00219 ** 
F.Undergrad -0.001069   0.000461   -2.32  0.02068 *  
P.Undergrad -0.001294   0.000444   -2.92  0.00369 ** 
Outstate     0.001782   0.000297    6.01  3.7e-09 ***
Room.Board   0.000871   0.000721    1.21  0.22790    
Books       -0.000932   0.004089   -0.23  0.81988    
Personal    -0.001457   0.000998   -1.46  0.14494    
PhD          0.104743   0.071027    1.47  0.14095    
Terminal    -0.101789   0.076321   -1.33  0.18293    
S.F.Ratio    0.275943   0.191423    1.44  0.15008    
perc.alumni  0.219944   0.061576    3.57  0.00039 ***
Expend      -0.000683   0.000202   -3.39  0.00077 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

(Dispersion parameter for gaussian family taken to be 155)

    Null deviance: 141641  on 499  degrees of freedom
Residual deviance:  74595  on 482  degrees of freedom
AIC: 3960

Number of Fisher Scoring iterations: 2</code></pre>
<ol start="4" style="list-style-type: decimal">
<li>Using <code>predict()</code> save the fitted values of <code>grad_glm</code> object as <code>glm_fit</code>:</li>
</ol>
<pre class="r"><code># Save fitted values of regression model
glm_fit &lt;- predict(XXX)</code></pre>
<pre class="r"><code>glm_fit &lt;- predict(grad_glm)</code></pre>
<ol start="5" style="list-style-type: decimal">
<li>Print your <code>glm_fit</code> object, look at summary statistics with <code>summary(glm_fit)</code>, and create a histogram with <code>hist()</code> do they make sense?</li>
</ol>
<pre class="r"><code># Explore regression model fits

XXX
summary(XXX)
hist(XXX)</code></pre>
<pre class="r"><code>glm_fit[1:10]   # Only printing first 5</code></pre>
<pre><code>   1    2    3    4    5    6    7    8    9   10 
71.8 56.4 91.8 62.9 69.2 68.5 57.4 52.0 57.4 71.0 </code></pre>
<pre class="r"><code>summary(glm_fit)</code></pre>
<pre><code>   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
   33.0    57.3    64.1    65.6    73.3   102.8 </code></pre>
<pre class="r"><code>hist(glm_fit)</code></pre>
<p><img src="Prediction_practical_files/figure-html/unnamed-chunk-26-1.png" width="576" style="display: block; margin: auto;" /></p>
</div>
<div id="decision-trees" class="section level3">
<h3>Decision Trees</h3>
<ol start="4" style="list-style-type: decimal">
<li>Using <code>train()</code>, fit a decision tree model called <code>grad_rpart</code></li>
</ol>
<ul>
<li>For the <code>form</code> argument, use <code>Grad.Rate ~ .</code></li>
<li>For the <code>data</code> argument, use <code>college_train</code> in the data argument</li>
<li>For the <code>method</code> argument, use <code>method = &quot;rpart&quot;</code> to create decision trees</li>
<li>For the <code>trControl</code> argument, use your <code>ctrl_none</code> object you created before</li>
<li>For the <code>tuneGrid</code> argument, use <code>cp = 0.01</code> to specify the value of the complexity parameter. This is a pretty low value which means your trees will be, relatively, complex.</li>
</ul>
<pre class="r"><code>grad_rpart &lt;- train(form = XX ~ .,
                  data = XXX,
                  method = &quot;XX&quot;,
                  trControl = XX,
                  tuneGrid = expand.grid(cp = XX))   # Set complexity parameter</code></pre>
<pre class="r"><code>grad_rpart &lt;- train(form = Grad.Rate ~ .,
                  data = college_train,
                  method = &quot;rpart&quot;,
                  trControl = ctrl_none,
                  tuneGrid = expand.grid(cp = .01))   # Set complexity parameter</code></pre>
<ol start="5" style="list-style-type: decimal">
<li>Explore your <code>grad_rpart</code> object by looking at <code>grad_rpart$finalModel</code> and plotting it with <code>plot(as.party(grad_rpart$finalModel))</code>, what do you find?</li>
</ol>
<pre class="r"><code>grad_rpart$finalModel</code></pre>
<pre><code>n= 500 

node), split, n, deviance, yval
      * denotes terminal node

 1) root 500 142000 65.6  
   2) Outstate&lt; 1.06e+04 292  69000 58.0  
     4) Top25perc&lt; 47.5 135  34100 53.3  
       8) Outstate&lt; 8.56e+03 86  20000 48.9  
        16) Expend&gt;=6.97e+03 26   6430 41.9 *
        17) Expend&lt; 6.97e+03 60  11700 52.0  
          34) Books&gt;=388 53   9310 50.0 *
          35) Books&lt; 388 7    639 66.7 *
       9) Outstate&gt;=8.56e+03 49   9520 61.1 *
     5) Top25perc&gt;=47.5 157  29600 61.9  
      10) Top10perc&lt; 51.5 147  26100 61.0  
        20) perc.alumni&lt; 24.5 110  16700 58.9 *
        21) perc.alumni&gt;=24.5 37   7500 67.2 *
      11) Top10perc&gt;=51.5 10   1570 75.3 *
   3) Outstate&gt;=1.06e+04 208  31500 76.4  
     6) Outstate&lt; 1.68e+04 158  21500 73.3  
      12) perc.alumni&lt; 22.5 55   8180 68.7 *
      13) perc.alumni&gt;=22.5 103  11500 75.8  
        26) F.Undergrad&lt; 1.42e+03 55   4770 71.2 *
        27) F.Undergrad&gt;=1.42e+03 48   4200 81.1 *
     7) Outstate&gt;=1.68e+04 50   4040 85.9 *</code></pre>
<pre class="r"><code>plot(as.party(grad_rpart$finalModel))</code></pre>
<p><img src="Prediction_practical_files/figure-html/unnamed-chunk-29-1.png" width="576" style="display: block; margin: auto;" /></p>
<ol start="6" style="list-style-type: decimal">
<li>Using <code>predict()</code> save the fitted values of <code>grad_rpart</code> object as <code>rpart_predfit</code>:</li>
</ol>
<pre class="r"><code># Save fitted values of decision tree model
rpart_predfit &lt;- predict(XXX)</code></pre>
<pre class="r"><code>rpart_predfit &lt;- predict(grad_rpart)</code></pre>
<ol start="7" style="list-style-type: decimal">
<li>Print your <code>rpart_predfit</code> object, look at summary statistics with <code>summary(rpart_predfit)</code>, and create a histogram with <code>hist()</code> do they make sense?</li>
</ol>
<pre class="r"><code># Explore decision tree fits

XXX
summary(XXX)
hist(XXX)</code></pre>
<pre class="r"><code>rpart_predfit[1:10] # Only first 10</code></pre>
<pre><code>   1    2    3    4    5    6    7    8    9   10 
71.2 58.9 85.9 58.9 68.7 81.1 58.9 50.0 50.0 81.1 </code></pre>
<pre class="r"><code>summary(rpart_predfit)</code></pre>
<pre><code>   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
   41.9    58.9    67.2    65.6    71.2    85.9 </code></pre>
<pre class="r"><code>hist(rpart_predfit)</code></pre>
<p><img src="Prediction_practical_files/figure-html/unnamed-chunk-33-1.png" width="576" style="display: block; margin: auto;" /></p>
</div>
<div id="random-forests" class="section level3">
<h3>Random Forests</h3>
<ol start="8" style="list-style-type: decimal">
<li>Using <code>train()</code>, fit a random forest model called <code>grad_rf</code></li>
</ol>
<ul>
<li>For the <code>form</code> argument, use <code>Grad.Rate ~ .</code></li>
<li>For the <code>data</code> argument, use <code>college_train</code> in the data argument</li>
<li>For the <code>method</code> argument, use <code>method = &quot;rf&quot;</code> to fit random forests</li>
<li>For the <code>trControl</code> argument, use your <code>ctrl_none</code> object you created before</li>
<li>For the <code>mtry</code> parameter, use <code>mtry</code> = 2. This is a relatively low value, so the forest will not be very diverse</li>
</ul>
<pre class="r"><code>grad_rf &lt;- train(form = XX ~ .,   # Predict grad and exclude college_name
                 data = XX,
                 method = &quot;XX&quot;,
                 trControl = XX,
                 tuneGrid = expand.grid(mtry = XX))  # Set number of features randomly selected</code></pre>
<pre class="r"><code>grad_rf &lt;- train(form = Grad.Rate ~ .,   # Predict grad and exclude college_name
                 data = college_train,
                 method = &quot;rf&quot;,
                 trControl = ctrl_none,
                 tuneGrid = expand.grid(mtry = 2))  # Set number of features randomly selected</code></pre>
<ol start="9" style="list-style-type: decimal">
<li>Using <code>predict()</code> save the fitted values of <code>grad_rf</code> object as <code>rf_fit</code>:</li>
</ol>
<pre class="r"><code># Save fitted values of random forest model
rf_fit &lt;- predict(XXX)</code></pre>
<pre class="r"><code>rf_fit &lt;- predict(grad_rf)</code></pre>
<ol start="10" style="list-style-type: decimal">
<li>Print your <code>rf_fit</code> object, look at summary statistics with <code>summary(rf_fit)</code>, and create a histogram with <code>hist()</code> do they make sense?</li>
</ol>
<pre class="r"><code># Explore random forest fits

XXX
summary(XXX)
hist(XXX)</code></pre>
<pre class="r"><code>rf_fit[1:10]    # Only first 10</code></pre>
<pre><code>   1    2    3    4    5    6    7    8    9   10 
69.1 63.7 85.3 55.9 76.6 66.2 58.1 44.0 58.4 73.0 </code></pre>
<pre class="r"><code>summary(rf_fit)</code></pre>
<pre><code>   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
   32.3    56.6    65.6    65.6    74.8    96.4 </code></pre>
<pre class="r"><code>hist(rf_fit)</code></pre>
<p><img src="Prediction_practical_files/figure-html/unnamed-chunk-39-1.png" width="576" style="display: block; margin: auto;" /></p>
</div>
<div id="assess-accuracy" class="section level3">
<h3>Assess accuracy</h3>
<ol start="11" style="list-style-type: decimal">
<li>Save the true training criterion values (<code>college_train$Grad.Rate</code>) as a vector called <code>criterion_train</code></li>
</ol>
<pre class="r"><code># Save training criterion values
criterion_train &lt;- XXX$XXX</code></pre>
<pre class="r"><code>criterion_train &lt;- college_train$Grad.Rate</code></pre>
<ol start="12" style="list-style-type: decimal">
<li>Using <code>postResample()</code>, determine the fitting performance of each of your models separately. Make sure to set your <code>criterion_train</code> values to the <code>obs</code> argument, and your true model fits <code>XX_fit</code> to the <code>pred</code> argument:</li>
</ol>
<pre class="r"><code># Calculate fitting accuracies of each model
# pred = XX_pred
# obs = criterion_train

# Regression
postResample(pred = XXX, obs = XXX)

# Decision Trees
postResample(pred = XXX, obs = XXX)

# Random Forests
postResample(pred = XXX, obs = XXX)</code></pre>
<pre class="r"><code># Regression
postResample(pred = glm_fit, obs = criterion_train)</code></pre>
<pre><code>    RMSE Rsquared      MAE 
  12.214    0.473    9.250 </code></pre>
<pre class="r"><code># Decision Trees
postResample(pred = rpart_predfit, obs = criterion_train)</code></pre>
<pre><code>    RMSE Rsquared      MAE 
  12.072    0.486    9.536 </code></pre>
<pre class="r"><code># Random Forests
postResample(pred = rpart_predfit, obs = criterion_train)</code></pre>
<pre><code>    RMSE Rsquared      MAE 
  12.072    0.486    9.536 </code></pre>
<ol start="13" style="list-style-type: decimal">
<li>Which one had the best fits? What was the fitting MAE of each model?</li>
</ol>
<p>(Optional). If you’d like to, try visualizing the fitting results using the plotting code shown in the Examples tab above. Ask for help if you need it!</p>
</div>
</div>
<div id="c---prediction" class="section level2">
<h2>C - Prediction</h2>
<ol style="list-style-type: decimal">
<li>Save the criterion values from the test data set <code>college_test$Grad.Rate</code> as a new vector called <code>criterion_test</code>:</li>
</ol>
<pre class="r"><code># Save criterion values
criterion_test &lt;- XXX$XXX</code></pre>
<ol start="2" style="list-style-type: decimal">
<li>Using <code>predict()</code>, save the predicted values of each model for the test data <code>college_test</code> as <code>glm_pred</code>, <code>rpart_pred</code> and <code>rf_pred</code>.</li>
</ol>
<pre class="r"><code># Save model predictions for test data
# newdata = college_test

# Regression
glm_pred &lt;- predict(XXX, newdata = XXX)

# Decision Trees
rpart_pred &lt;- predict(XXX, newdata = XXX)

# Random Forests
rf_pred &lt;- predict(XXX, newdata = XXX)</code></pre>
<ol start="3" style="list-style-type: decimal">
<li>Using <code>postResample()</code>, determine the <em>prediction</em> performance of each of your models against the test criterion <code>criterion_test</code>.</li>
</ol>
<pre class="r"><code># Calculate prediction accuracies of each model
# obs = criterion_test
# pred = XX_pred

# Regression
postResample(pred = XXX, obs = XXX)

# Decision Trees
postResample(pred = XXX, obs = XXX)

# Random Forests
postResample(pred = XXX, obs = XXX)</code></pre>
<ol start="4" style="list-style-type: decimal">
<li><p>How does each model’s <em>prediction / test</em> performance (on the <code>XXX_test</code> data) compare to its <em>fitting / training</em> performance (on the <code>XXX_train</code> data)? Is it worse? Better? The same? What does the change tell you about the models?</p></li>
<li><p>Which of the three models has the best prediction performance?</p></li>
<li><p>If you had to use one of these three models in the real-world, which one would it be? Why?</p></li>
<li><p>If someone came to you and asked “If I use your model in the future to predict the graduation rate of a new college, how accurate do you think it would be?”, what would you say?</p></li>
</ol>
</div>
</div>
<div id="house-prices-in-king-county-washington" class="section level1">
<h1>House Prices in King County, Washington</h1>
<p>In this section, we will predict the prices of houses in King County Washington (home of Seattle, <a href="https://qz.com/208457/a-cartographic-guide-to-starbucks-global-domination/">which you can thank for this</a>) using the <code>house_train</code> and <code>house_test</code> datasets. Here’s how they should look:</p>
<table>
<thead>
<tr class="header">
<th align="right">price</th>
<th align="right">bedrooms</th>
<th align="right">bathrooms</th>
<th align="right">sqft_living</th>
<th align="right">sqft_lot</th>
<th align="right">floors</th>
<th align="right">waterfront</th>
<th align="right">view</th>
<th align="right">condition</th>
<th align="right">grade</th>
<th align="right">sqft_above</th>
<th align="right">sqft_basement</th>
<th align="right">yr_built</th>
<th align="right">yr_renovated</th>
<th align="right">zipcode</th>
<th align="right">lat</th>
<th align="right">long</th>
<th align="right">sqft_living15</th>
<th align="right">sqft_lot15</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">176000</td>
<td align="right">2</td>
<td align="right">1.00</td>
<td align="right">770</td>
<td align="right">5200</td>
<td align="right">1.0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">5</td>
<td align="right">6</td>
<td align="right">770</td>
<td align="right">0</td>
<td align="right">1969</td>
<td align="right">0</td>
<td align="right">98042</td>
<td align="right">47.4</td>
<td align="right">-122</td>
<td align="right">1150</td>
<td align="right">5330</td>
</tr>
<tr class="even">
<td align="right">370000</td>
<td align="right">2</td>
<td align="right">1.00</td>
<td align="right">850</td>
<td align="right">6213</td>
<td align="right">1.0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">3</td>
<td align="right">6</td>
<td align="right">750</td>
<td align="right">100</td>
<td align="right">1916</td>
<td align="right">0</td>
<td align="right">98136</td>
<td align="right">47.5</td>
<td align="right">-122</td>
<td align="right">1880</td>
<td align="right">5500</td>
</tr>
<tr class="odd">
<td align="right">875909</td>
<td align="right">4</td>
<td align="right">2.50</td>
<td align="right">3610</td>
<td align="right">13292</td>
<td align="right">2.0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">3</td>
<td align="right">10</td>
<td align="right">3610</td>
<td align="right">0</td>
<td align="right">1996</td>
<td align="right">0</td>
<td align="right">98075</td>
<td align="right">47.6</td>
<td align="right">-122</td>
<td align="right">3000</td>
<td align="right">10776</td>
</tr>
<tr class="even">
<td align="right">100000</td>
<td align="right">2</td>
<td align="right">1.00</td>
<td align="right">770</td>
<td align="right">17334</td>
<td align="right">1.0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">3</td>
<td align="right">7</td>
<td align="right">770</td>
<td align="right">0</td>
<td align="right">1978</td>
<td align="right">0</td>
<td align="right">98001</td>
<td align="right">47.3</td>
<td align="right">-122</td>
<td align="right">1480</td>
<td align="right">17334</td>
</tr>
<tr class="odd">
<td align="right">580000</td>
<td align="right">3</td>
<td align="right">1.75</td>
<td align="right">1850</td>
<td align="right">2797</td>
<td align="right">1.0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">3</td>
<td align="right">8</td>
<td align="right">1150</td>
<td align="right">700</td>
<td align="right">1977</td>
<td align="right">0</td>
<td align="right">98103</td>
<td align="right">47.7</td>
<td align="right">-122</td>
<td align="right">1450</td>
<td align="right">4599</td>
</tr>
<tr class="even">
<td align="right">577000</td>
<td align="right">5</td>
<td align="right">2.75</td>
<td align="right">1940</td>
<td align="right">5000</td>
<td align="right">2.0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">5</td>
<td align="right">7</td>
<td align="right">1940</td>
<td align="right">0</td>
<td align="right">1951</td>
<td align="right">0</td>
<td align="right">98107</td>
<td align="right">47.7</td>
<td align="right">-122</td>
<td align="right">1940</td>
<td align="right">4230</td>
</tr>
<tr class="odd">
<td align="right">665000</td>
<td align="right">4</td>
<td align="right">2.50</td>
<td align="right">2600</td>
<td align="right">17388</td>
<td align="right">2.0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">3</td>
<td align="right">9</td>
<td align="right">2600</td>
<td align="right">0</td>
<td align="right">1996</td>
<td align="right">0</td>
<td align="right">98059</td>
<td align="right">47.5</td>
<td align="right">-122</td>
<td align="right">2950</td>
<td align="right">11553</td>
</tr>
<tr class="even">
<td align="right">425000</td>
<td align="right">3</td>
<td align="right">1.50</td>
<td align="right">1970</td>
<td align="right">13709</td>
<td align="right">1.0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">4</td>
<td align="right">7</td>
<td align="right">1680</td>
<td align="right">290</td>
<td align="right">1955</td>
<td align="right">0</td>
<td align="right">98155</td>
<td align="right">47.8</td>
<td align="right">-122</td>
<td align="right">2200</td>
<td align="right">16536</td>
</tr>
<tr class="odd">
<td align="right">225000</td>
<td align="right">3</td>
<td align="right">1.00</td>
<td align="right">660</td>
<td align="right">6600</td>
<td align="right">1.0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">4</td>
<td align="right">5</td>
<td align="right">660</td>
<td align="right">0</td>
<td align="right">1940</td>
<td align="right">0</td>
<td align="right">98168</td>
<td align="right">47.5</td>
<td align="right">-122</td>
<td align="right">1320</td>
<td align="right">6600</td>
</tr>
<tr class="even">
<td align="right">660000</td>
<td align="right">5</td>
<td align="right">2.25</td>
<td align="right">2540</td>
<td align="right">3750</td>
<td align="right">1.5</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">4</td>
<td align="right">7</td>
<td align="right">1510</td>
<td align="right">1030</td>
<td align="right">1925</td>
<td align="right">0</td>
<td align="right">98115</td>
<td align="right">47.7</td>
<td align="right">-122</td>
<td align="right">1780</td>
<td align="right">3750</td>
</tr>
</tbody>
</table>
<div id="a---setup-1" class="section level2">
<h2>A - Setup</h2>
<ol style="list-style-type: decimal">
<li><p>Make sure you are still working in your <code>BaselRBootcamp</code> R project, with the folders <code>1_Data</code> and <code>2_Code</code>. Make sure that the data file(s) listed in the <code>Datasets</code> section above are in your <code>1_Data</code> folder</p></li>
<li>Open a new R script. At the top of the script, using comments, write your name and the date. Save it as a new file called <code>Prediction_HousePrices_practical.R</code> in the <code>2_Code</code> folder.<br />
</li>
<li><p>Using <code>library()</code> load the set of packages for this practical listed in the packages section above.</p></li>
</ol>
<pre class="r"><code>## NAME
## DATE
## Fitting Practical - House Prices Prediction

library(tidyverse)
library(caret)
library(party)
library(partykit)</code></pre>
<ol start="4" style="list-style-type: decimal">
<li>Run the code below to load each of the datasets listed in the <code>Datasets</code> as new objects</li>
</ol>
<pre class="r"><code># house data
house_train &lt;- read_csv(file = &quot;1_Data/house_train.csv&quot;)
house_test &lt;- read_csv(file = &quot;1_Data/house_test.csv&quot;)</code></pre>
<ol start="5" style="list-style-type: decimal">
<li><p>Take a look at the first few rows of each dataframe by printing then to the console.</p></li>
<li><p>Print the numbers of rows and columns of each dataset using the <code>dim()</code> function</p></li>
</ol>
<pre class="r"><code># Print numbers of rows and columns

dim(XXX)
dim(XXX)</code></pre>
<ol start="7" style="list-style-type: decimal">
<li>Look at the names of the dataframes with the <code>names()</code> function.</li>
</ol>
<pre class="r"><code># Print the names of each dataframe

names(XXX)
names(XXX)</code></pre>
<ol start="8" style="list-style-type: decimal">
<li>Open each dataset in a new window using <code>View()</code>. Do they look ok?</li>
</ol>
<pre class="r"><code># Open each dataset in a window.

View(XXX)
View(XXX)</code></pre>
<ol start="9" style="list-style-type: decimal">
<li>We need to do a little bit of data cleaning before starting. Specifically, we need to convert all character columsn to factor: Do this by running the following code:</li>
</ol>
<pre class="r"><code># Convert all character columns to factor

house_train &lt;- house_train %&gt;%
          mutate_if(is.character, factor)

house_test &lt;- house_test %&gt;%
          mutate_if(is.character, factor)</code></pre>
</div>
<div id="b---fitting-1" class="section level2">
<h2>B - Fitting</h2>
<p>Your goal in the following models is to predict <code>price</code>, the selling price of homes in King County WA.</p>
<ol style="list-style-type: decimal">
<li>Using <code>trainControl()</code>, set your training control method to <code>&quot;none&quot;</code>. Save your object as <code>ctrl_none</code>.</li>
</ol>
<pre class="r"><code># Set training method to &quot;none&quot; for simple fitting
#  Note: This is for demonstration purposes, you would almost
#   never do this for a &#39;real&#39; prediction task!

ctrl_none &lt;- trainControl(method = &quot;XXX&quot;)</code></pre>
<pre class="r"><code>ctrl_none &lt;- trainControl(method = &quot;none&quot;)</code></pre>
<div id="regression-1" class="section level3">
<h3>Regression</h3>
<ol start="2" style="list-style-type: decimal">
<li>Using <code>train()</code> fit a regression model called <code>price_glm</code> predicting <code>price</code> using all features in <code>house_train</code>.</li>
</ol>
<ul>
<li>For the <code>form</code> argument, use <code>price ~ .</code></li>
<li>For the <code>data</code> argument, use <code>house_train</code> in the data argument</li>
<li>For the <code>method</code> argument, use <code>method = &quot;glm&quot;</code> for regression</li>
<li>For the <code>trControl</code> argument, use your <code>ctrl_none</code> object you created before</li>
</ul>
<pre class="r"><code>price_glm &lt;- train(form = XX ~ .,
                  data = XX,
                  method = &quot;XXX&quot;,
                  trControl = ctrl_none)</code></pre>
<pre class="r"><code>price_glm &lt;- train(form = price ~ .,
                  data = house_train,
                  method = &quot;glm&quot;,
                  trControl = ctrl_none)</code></pre>
<ol start="3" style="list-style-type: decimal">
<li>Explore your <code>price_glm</code> object by looking at <code>price_glm$finalModel</code> and using <code>summary()</code>, what do you find?</li>
</ol>
<pre class="r"><code>price_glm$XXX
summary(XXX)</code></pre>
<pre class="r"><code>price_glm$finalModel</code></pre>
<pre><code>
Call:  NULL

Coefficients:
  (Intercept)       bedrooms      bathrooms    sqft_living       sqft_lot  
     1.07e+05      -4.64e+04       5.35e+04       1.47e+02       2.31e-01  
       floors     waterfront           view      condition          grade  
     5.03e+03       6.40e+05       5.84e+04       3.03e+04       9.74e+04  
   sqft_above  sqft_basement       yr_built   yr_renovated        zipcode  
     2.40e+01             NA      -2.61e+03       4.31e+00      -5.42e+02  
          lat           long  sqft_living15     sqft_lot15  
     6.14e+05      -2.32e+05       2.71e+01      -2.63e-01  

Degrees of Freedom: 4999 Total (i.e. Null);  4982 Residual
Null Deviance:      6.81e+14 
Residual Deviance: 2.02e+14     AIC: 136000</code></pre>
<pre class="r"><code>summary(price_glm)</code></pre>
<pre><code>
Call:
NULL

Deviance Residuals: 
     Min        1Q    Median        3Q       Max  
-1114590    -98269    -10834     76308   4063119  

Coefficients: (1 not defined because of singularities)
               Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)    1.07e+05   6.13e+06    0.02  0.98603    
bedrooms      -4.64e+04   4.14e+03  -11.19  &lt; 2e-16 ***
bathrooms      5.35e+04   7.00e+03    7.65  2.4e-14 ***
sqft_living    1.47e+02   9.33e+00   15.73  &lt; 2e-16 ***
sqft_lot       2.31e-01   1.02e-01    2.26  0.02360 *  
floors         5.03e+03   7.62e+03    0.66  0.50982    
waterfront     6.40e+05   3.53e+04   18.14  &lt; 2e-16 ***
view           5.84e+04   4.52e+03   12.94  &lt; 2e-16 ***
condition      3.03e+04   4.82e+03    6.28  3.6e-10 ***
grade          9.74e+04   4.43e+03   21.99  &lt; 2e-16 ***
sqft_above     2.40e+01   9.25e+00    2.60  0.00935 ** 
sqft_basement        NA         NA      NA       NA    
yr_built      -2.61e+03   1.54e+02  -16.92  &lt; 2e-16 ***
yr_renovated   4.31e+00   7.99e+00    0.54  0.58986    
zipcode       -5.42e+02   6.84e+01   -7.92  3.0e-15 ***
lat            6.14e+05   2.25e+04   27.28  &lt; 2e-16 ***
long          -2.32e+05   2.71e+04   -8.55  &lt; 2e-16 ***
sqft_living15  2.71e+01   7.12e+00    3.81  0.00014 ***
sqft_lot15    -2.63e-01   1.60e-01   -1.64  0.10008    
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

(Dispersion parameter for gaussian family taken to be 4.06e+10)

    Null deviance: 6.8104e+14  on 4999  degrees of freedom
Residual deviance: 2.0203e+14  on 4982  degrees of freedom
AIC: 136339

Number of Fisher Scoring iterations: 2</code></pre>
<ol start="4" style="list-style-type: decimal">
<li>Using <code>predict()</code> save the fitted values of <code>price_glm</code> object as <code>glm_fit</code>:</li>
</ol>
<pre class="r"><code># Save fitted values of regression model
glm_fit &lt;- predict(XXX)</code></pre>
<pre class="r"><code># Save fitted values of regression model
glm_fit &lt;- predict(price_glm)</code></pre>
<ol start="5" style="list-style-type: decimal">
<li>Print your <code>glm_fit</code> object, look at summary statistics with <code>summary(glm_fit)</code>, and create a histogram with <code>hist()</code> do they make sense?</li>
</ol>
<pre class="r"><code># Explore regression model fits

XXX
summary(XXX)
hist(XXX)</code></pre>
<pre class="r"><code>glm_fit[1:10]  # Only first 10</code></pre>
<pre><code>     1      2      3      4      5      6      7      8      9     10 
 47648 276160 927614  95201 553709 590318 669722 581335  -2308 654493 </code></pre>
<pre class="r"><code>summary(glm_fit)</code></pre>
<pre><code>   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
-414135  335260  487481  536998  672715 2821881 </code></pre>
<pre class="r"><code>hist(glm_fit)</code></pre>
<p><img src="Prediction_practical_files/figure-html/unnamed-chunk-65-1.png" width="576" style="display: block; margin: auto;" /></p>
</div>
<div id="decision-trees-1" class="section level3">
<h3>Decision Trees</h3>
<ol start="4" style="list-style-type: decimal">
<li>Using <code>train()</code>, fit a decision tree model called <code>price_rpart</code> predicting <code>price</code> using all features in <code>house_train</code>.</li>
</ol>
<ul>
<li>For the <code>form</code> argument, use <code>price ~ .</code></li>
<li>For the <code>data</code> argument, use <code>house_train</code> in the data argument</li>
<li>For the <code>method</code> argument, use <code>method = &quot;rpart&quot;</code> to create decision trees</li>
<li>For the <code>trControl</code> argument, use your <code>ctrl_none</code> object you created before</li>
<li>For the <code>tuneGrid</code> argument, use <code>cp = 0.01</code> to specify the value of the complexity parameter. This is a pretty low value which means your trees will be, relatively, complex.</li>
</ul>
<pre class="r"><code>price_rpart &lt;- train(form = XX ~ .,
                  data = XXX,
                  method = &quot;XX&quot;,
                  trControl = XX,
                  tuneGrid = expand.grid(cp = XX))   # Set complexity parameter</code></pre>
<pre class="r"><code>price_rpart &lt;- train(form = price ~ .,
                  data = house_train,
                  method = &quot;rpart&quot;,
                  trControl = ctrl_none,
                  tuneGrid = expand.grid(cp = .01))   # Set complexity parameter</code></pre>
<ol start="5" style="list-style-type: decimal">
<li>Explore your <code>price_rpart</code> object by looking at <code>price_rpart$finalModel</code> and plotting it with <code>plot(as.party(price_rpart$finalModel))</code>, what do you find?</li>
</ol>
<pre class="r"><code>price_rpart</code></pre>
<pre><code>CART 

5000 samples
  18 predictor

No pre-processing
Resampling: None </code></pre>
<pre class="r"><code>plot(as.party(price_rpart$finalModel))</code></pre>
<p><img src="Prediction_practical_files/figure-html/unnamed-chunk-68-1.png" width="576" style="display: block; margin: auto;" /></p>
<ol start="6" style="list-style-type: decimal">
<li>Using <code>predict()</code> save the fitted values of <code>price_rpart</code> object as <code>rpart_predfit</code>:</li>
</ol>
<pre class="r"><code># Save fitted values of decision tree model
rpart_predfit &lt;- predict(XXX)</code></pre>
<pre class="r"><code>rpart_predfit &lt;- predict(price_rpart)</code></pre>
<ol start="7" style="list-style-type: decimal">
<li>Print your <code>rpart_predfit</code> object, look at summary statistics with <code>summary(rpart_predfit)</code>, and create a histogram with <code>hist()</code> do they make sense?</li>
</ol>
<pre class="r"><code># Explore decision tree fits

XXX
summary(XXX)
hist(XXX)</code></pre>
<pre class="r"><code>rpart_predfit[1:10]   # Only first 10 values</code></pre>
<pre><code>     1      2      3      4      5      6      7      8      9     10 
267637 267637 921645 267637 553958 553958 407649 553958 267637 674757 </code></pre>
<pre class="r"><code>summary(rpart_predfit)</code></pre>
<pre><code>   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 267637  407649  424548  536998  553958 3144305 </code></pre>
<pre class="r"><code>hist(rpart_predfit)</code></pre>
<p><img src="Prediction_practical_files/figure-html/unnamed-chunk-72-1.png" width="576" style="display: block; margin: auto;" /></p>
</div>
<div id="random-forests-1" class="section level3">
<h3>Random Forests</h3>
<ol start="8" style="list-style-type: decimal">
<li>Using <code>train()</code>, fit a random forest model called <code>price_rf</code> predicting <code>price</code> using all features in <code>house_train</code>.</li>
</ol>
<ul>
<li>For the <code>form</code> argument, use <code>price ~ .</code></li>
<li>For the <code>data</code> argument, use <code>house_train</code> in the data argument</li>
<li>For the <code>method</code> argument, use <code>method = &quot;rf&quot;</code> to fit random forests</li>
<li>For the <code>trControl</code> argument, use your <code>ctrl_none</code> object you created before</li>
<li>For the <code>mtry</code> parameter, use <code>mtry</code> = 2. This is a relatively low value, so the forest will not be very diverse</li>
</ul>
<pre class="r"><code>price_rf &lt;- train(form = XX ~ . - XX - XX,   # Predict price and exclude id and date
                 data = XX,
                 method = &quot;XX&quot;,
                 trControl = XX,
                 tuneGrid = expand.grid(mtry = XX))  # Set number of features randomly selected</code></pre>
<pre class="r"><code>price_rf &lt;- train(form = price ~ .,   # Predict price and exclude id and date
                 data = house_train,
                 method = &quot;rf&quot;,
                 trControl = ctrl_none,
                 tuneGrid = expand.grid(mtry = 2))  # Set number of features randomly selected</code></pre>
<ol start="9" style="list-style-type: decimal">
<li>Using <code>predict()</code> save the fitted values of <code>price_rf</code> object as <code>rf_fit</code>:</li>
</ol>
<pre class="r"><code># Save fitted values of random forest model
rf_fit &lt;- predict(XXX)</code></pre>
<pre class="r"><code>rf_fit &lt;- predict(price_rf)</code></pre>
<ol start="10" style="list-style-type: decimal">
<li>Print your <code>rf_fit</code> object, look at summary statistics with <code>summary(rf_fit)</code>, and create a histogram with <code>hist()</code> do they make sense?</li>
</ol>
<pre class="r"><code># Explore random forest fits

XXX
summary(XXX)
hist(XXX)</code></pre>
<pre class="r"><code>rf_fit[1:10]   # Only first 10 cases</code></pre>
<pre><code>     1      2      3      4      5      6      7      8      9     10 
193203 352572 839063 163852 552803 622876 654858 445099 215508 682246 </code></pre>
<pre class="r"><code>summary(rf_fit)</code></pre>
<pre><code>   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 150344  338382  460445  536739  631408 4976947 </code></pre>
<pre class="r"><code>hist(rf_fit)</code></pre>
<p><img src="Prediction_practical_files/figure-html/unnamed-chunk-78-1.png" width="576" style="display: block; margin: auto;" /></p>
</div>
<div id="assess-accuracy-1" class="section level3">
<h3>Assess accuracy</h3>
<ol start="11" style="list-style-type: decimal">
<li>Save the true training criterion values (<code>house_train$price</code>) as a vector called <code>criterion_train</code></li>
</ol>
<pre class="r"><code># Save training criterion values
criterion_train &lt;- XXX$XXX</code></pre>
<pre class="r"><code>criterion_train &lt;- house_train$price</code></pre>
<ol start="12" style="list-style-type: decimal">
<li>Using <code>postResample()</code>, determine the fitting performance of each of your models separately. Make sure to set your <code>criterion_train</code> values to the <code>obs</code> argument, and your true model fits <code>XX_fit</code> to the <code>pred</code> argument:</li>
</ol>
<pre class="r"><code># Calculate fitting accuracies of each model
# pred = XX_fit
# obs = criterion_train

# Regression
postResample(pred = XXX, obs = XXX)

# Decision Trees
postResample(pred = XXX, obs = XXX)

# Random Forests
postResample(pred = XXX, obs = XXX)</code></pre>
<pre class="r"><code># Calculate fitting accuracies of each model
# pred = XX_fit
# obs = criterion_train

# Regression
postResample(pred = glm_fit, obs = criterion_train)</code></pre>
<pre><code>    RMSE Rsquared      MAE 
2.01e+05 7.03e-01 1.25e+05 </code></pre>
<pre class="r"><code># Decision Trees
postResample(pred = rpart_predfit, obs = criterion_train)</code></pre>
<pre><code>    RMSE Rsquared      MAE 
1.94e+05 7.23e-01 1.19e+05 </code></pre>
<pre class="r"><code># Random Forests
postResample(pred = rf_fit, obs = criterion_train)</code></pre>
<pre><code>    RMSE Rsquared      MAE 
7.93e+04 9.67e-01 4.36e+04 </code></pre>
<ol start="13" style="list-style-type: decimal">
<li>Which one had the best fits? What was the fitting MAE of each model?</li>
</ol>
<p>(Optional). If you’d like to, try visualizing the fitting results using the plotting code shown in the Examples tab above. Ask for help if you need it!</p>
<pre class="r"><code># Tidy competition results
accuracy &lt;- tibble(criterion_train = criterion_train,
                   Regression = glm_fit,
                   DecisionTrees = rpart_predfit,
                   RandomForest = rf_fit) %&gt;%
               gather(model, prediction, -criterion_train) %&gt;%
  
  # Add error measures
  mutate(se = prediction - criterion_train,
         ae = abs(prediction - criterion_train))

# Calculate summaries
accuracy_agg &lt;- accuracy %&gt;%
                  group_by(model) %&gt;%
                  summarise(mae = mean(ae))   # Calculate MAE (mean absolute error)

# Plot A) Scatterplot of truth versus predictions

ggplot(data = accuracy,
       aes(x = criterion_train, y = prediction, col = model)) +
  geom_point(alpha = .5) +
  geom_abline(slope = 1, intercept = 0) +
  labs(title = &quot;Predicting Housing Prices&quot;,
       subtitle = &quot;Black line indicates perfect performance&quot;)</code></pre>
<p><img src="Prediction_practical_files/figure-html/unnamed-chunk-83-1.png" width="576" style="display: block; margin: auto;" /></p>
<pre class="r"><code># Plot B) Violin plot of absolute errors

ggplot(data = accuracy, 
       aes(x = model, y = ae, fill = model)) + 
  geom_violin() + 
  geom_jitter(width = .05, alpha = .2) +
  labs(title = &quot;Prediction Absolute Errors&quot;,
       subtitle = &quot;Numbers indicate means&quot;,
       x = &quot;Model&quot;,
       y = &quot;Absolute Error&quot;) +
  guides(fill = FALSE) +
  annotate(geom = &quot;label&quot;, 
           x = accuracy_agg$model, 
           y = accuracy_agg$mae, 
           label = round(accuracy_agg$mae, 2))</code></pre>
<p><img src="Prediction_practical_files/figure-html/unnamed-chunk-83-2.png" width="576" style="display: block; margin: auto;" /></p>
</div>
</div>
<div id="c---prediction-1" class="section level2">
<h2>C - Prediction</h2>
<ol style="list-style-type: decimal">
<li>Save the criterion values from the test data set <code>house_test$price</code> as a new vector called <code>criterion_test</code>:</li>
</ol>
<pre class="r"><code># Save criterion values
criterion_test &lt;- XXX$XXX</code></pre>
<pre class="r"><code>criterion_test &lt;- house_test$price</code></pre>
<ol start="2" style="list-style-type: decimal">
<li>Using <code>predict()</code>, save the predicted values of each model for the test data <code>house_test</code> as <code>glm_pred</code>, <code>rpart_pred</code> and <code>rf_pred</code>.</li>
</ol>
<pre class="r"><code># Save model predictions for test data
# object: price_XXX
# newdata: college_test

# Regression
glm_pred &lt;- predict(XXX, newdata = XXX)

# Decision Trees
rpart_pred &lt;- predict(XXX, newdata = XXX)

# Random Forests
rf_pred &lt;- predict(XXX, newdata = XXX)</code></pre>
<pre class="r"><code># Regression
glm_pred &lt;- predict(price_glm, 
                    newdata = house_test)

# Decision Trees
rpart_pred &lt;- predict(price_rpart, 
                   newdata = house_test)

# Random Forests
rf_pred &lt;- predict(price_rf, 
                   newdata = house_test)</code></pre>
<ol start="3" style="list-style-type: decimal">
<li>Using <code>postResample()</code>, determine the <em>prediction</em> performance of each of your models against the test criterion <code>criterion_test</code>.</li>
</ol>
<pre class="r"><code># Calculate prediction accuracies of each model
# obs = criterion_test
# pred = XX_pred

# Regression
postResample(pred = XXX, obs = XXX)

# Decision Trees
postResample(pred = XXX, obs = XXX)

# Random Forests
postResample(pred = XXX, obs = XXX)</code></pre>
<pre class="r"><code># Regression
postResample(pred = glm_pred, obs = criterion_test)</code></pre>
<pre><code>    RMSE Rsquared      MAE 
1.92e+05 7.03e-01 1.26e+05 </code></pre>
<pre class="r"><code># Decision Trees
postResample(pred = rpart_pred, obs = criterion_test)</code></pre>
<pre><code>    RMSE Rsquared      MAE 
1.84e+05 7.25e-01 1.22e+05 </code></pre>
<pre class="r"><code># Random Forests
postResample(pred = rf_pred, obs = criterion_test)</code></pre>
<pre><code>    RMSE Rsquared      MAE 
1.42e+05 8.56e-01 8.09e+04 </code></pre>
<ol start="4" style="list-style-type: decimal">
<li><p>How does each model’s <em>prediction / test</em> performance (on the <code>XXX_test</code> data) compare to its <em>fitting / training</em> performance (on the <code>XXX_train</code> data)? Is it worse? Better? The same? What does the change tell you about the models?</p></li>
<li><p>Which of the three models has the best prediction performance?</p></li>
<li><p>If you had to use one of these three models in the real-world, which one would it be? Why?</p></li>
<li><p>If someone came to you and asked “If I use your model in the future to predict the graduation rate of a new college, how accurate do you think it would be?”, what would you say?</p></li>
</ol>
</div>
</div>
<div id="d---exploring-model-tuning-parameters" class="section level1">
<h1>D - Exploring model tuning parameters</h1>
<ol style="list-style-type: decimal">
<li><p>In all of your decision tree models so far, you have been setting the complexity parameter to 0.01. Try setting it to a larger value of 0.2 and see how your decision trees change (by plotting them). Do they get more or less complicated? How does increasing this value affect fitting and prediction performance? If you are interested in learning more about this parameter, look at the help menu with <code>?rpart.control</code>.</p></li>
<li><p>In each of your random forest models, you have been setting the <code>mtry</code> argument to 2. Try setting it to a larger value such as 5 and re-running your models. How does increasing this value affect fitting and prediction performance? If you are interested in learning more about this parameter, look at the help menu with <code>?randomForest</code>.</p></li>
<li><p>By default, the <code>train()</code> function uses 500 trees in <code>method = &quot;rf&quot;</code>. How do the number of trees affect performance? To answer this, try setting the number of trees to 1,000 (see example below) and re-evaluating your model’s training and test performance. What do you find? What if you set the number of trees to just 10?</p></li>
</ol>
<pre class="r"><code># Create random forest model with 1000 trees

mod &lt;- train(form = hwy ~ year + cyl + displ,
             data = data_train,
             method = &quot;rf&quot;,
             trControl = train_control,
             ntree = 1000,   # use 1000 trees! (Instead of the default value of 500)
             tuneGrid = expand.grid(mtry = 2))</code></pre>
</div>
<div id="z---challenges" class="section level1">
<h1>Z - Challenges</h1>
<ol style="list-style-type: decimal">
<li><p>So far you’ve probably been using most, if not all, available features in predicting house sales. But imagine someone came to you and said “I need to know how much a set of new houses will sell for, but I only have access to three features <code>bedrooms</code>, <code>bathrooms</code>, and <code>sqft_living</code>. Which of your models should I use and how accurate will they be? How would you answer that question? Use your modelling techniques to find out!</p></li>
<li><p>Repeat your modelling process, but now do a classification task. Specifically, predict whether or not a house sells for at least $1,000,000. To do this, you’ll first need to create a new column called <code>million</code> in both your <code>house_train</code> and <code>house_test</code> datasets (the code below should help you). Then, use your best modelling techniques to make this prediction. How accurate are your models in predicting whether or not a house will sell for over $1,000,000? Don’t forget to use the <code>confusionMatrix()</code> function instead of <code>postResample()</code> to evaluate your model’s accuracy!</p></li>
</ol>
<pre class="r"><code># Add million column to house_train and house_test
#  A factor indicating whether or not a house sells for
#   over 1,000,0000

house_train &lt;- house_train %&gt;%
  mutate(million = factor(price &gt; 1000000))

house_test &lt;- house_test %&gt;%
  mutate(million = factor(price &gt; 1000000))</code></pre>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
