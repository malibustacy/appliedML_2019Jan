---
title: "Features"
author: "Applied Machine Learning with R<br/><a href='https://therbootcamp.github.io'>www.therbootcamp.com</a><br/><a href='https://twitter.com/therbootcamp'>@therbootcamp</a>"
date: "January 2019"
output:
  xaringan::moon_reader:
    css: ["default", "baselrbootcamp.css"]
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      ratio: '16:9'
---

layout: true

<div class="my-footer"><span>
<a href="https://therbootcamp.github.io/"><font color="#7E7E7E">Applied Machine Learning with R, January 2019</font></a>
&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;
<a href="https://therbootcamp.github.io/"><font color="#7E7E7E">www.therbootcamp.com</font></a>
</span></div> 

---

```{r, eval = TRUE, echo = FALSE, warning=F,message=F}
# Code to knit slides
baselers <- readr::read_csv("../_data/baselers.csv")
```


```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
# see: https://github.com/yihui/xaringan
# install.packages("xaringan")
# see: 
# https://github.com/yihui/xaringan/wiki
# https://github.com/gnab/remark/wiki/Markdown
options(width=110)
options(digits = 4)
```

```{r, echo = FALSE ,message = FALSE, warning = FALSE}
knitr::opts_chunk$set(comment=NA, fig.width=6, fig.height=6, echo = TRUE, eval = TRUE, 
                      message = FALSE, warning = FALSE, fig.align = 'center', dpi = 200)
library(tidyverse)
library(baselers)
library(ggthemes)
```


---

# Problems

Too many features -> curse of dimensionality

Wrong features 
  in face of truth -> feature generation
  in face of data -> reverse engineering (black vs. white box)

Psychology
  

.pull-left4[

#  

]

.pull-right6[

]

---

.pull-left5[

# Feature importance

Regardless of the model you use, you will often want to know <high>which features are important</high> in predicting the criterion.

Often displayed on a *relative* scale from 0 to 100

Every model has their own definition of importance (see [the caret documentation](http://topepo.github.io/caret/variable-importance.html) for details).

Different models can give you different importance rankings (ML is fun!)

```{r, echo = FALSE, out.width = "40%"}
knitr::include_graphics("http://worldartsme.com/images/scale-clipart-1.jpg")
```


]

.pull-right45[

### Variable importance plot

Here's an example variable importance plot from R

```{r, echo = FALSE, out.width = "100%"}
knitr::include_graphics("http://mgel2011-kvm.env.duke.edu/mget/files/2012/07/RandomForestImportance.png")
```

]

---

.pull-left5[

## `varImp()`


Use `varImp()` to extract <high>variable importance</high> from a model


```{r}
# Get veriable importance from glm_train
varImp(glm_train)
```    
    
  
]

.pull-right45[
<br><br><br>
You can also plot the results using `plot()`

```{r, fig.width = 3, fig.height = 5, out.width = "50%"}
# Plot variable importance

plot(varImp(glm_train))
```


]


---

.pull-left4[

# Neural Networks

- Regularisation
- Complexity

]

.pull-right6[

]

